{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOX Word Clouds #\n",
    "\n",
    "In this notebook, I will view wordclouds from 12 months of FOX news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>sentence</th>\n",
       "      <th>start_snip</th>\n",
       "      <th>end_snip</th>\n",
       "      <th>contributor</th>\n",
       "      <th>runtime</th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>identifier</th>\n",
       "      <th>subjects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>week.</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>FOXNEWSW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 01:00:00</td>\n",
       "      <td>2019-05-28 02:00:59</td>\n",
       "      <td>FOXNEWSW_20190528_010000_Hannity_Memorial_Day_...</td>\n",
       "      <td>['biden', 'russia', 'alec baldwin', 'donald tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>tucker: tune in every night to the sworn enem...</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>FOXNEWSW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 01:00:00</td>\n",
       "      <td>2019-05-28 02:00:59</td>\n",
       "      <td>FOXNEWSW_20190528_010000_Hannity_Memorial_Day_...</td>\n",
       "      <td>['biden', 'russia', 'alec baldwin', 'donald tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>have a great memorial day evening. see you tom...</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>FOXNEWSW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 01:00:00</td>\n",
       "      <td>2019-05-28 02:00:59</td>\n",
       "      <td>FOXNEWSW_20190528_010000_Hannity_Memorial_Day_...</td>\n",
       "      <td>['biden', 'russia', 'alec baldwin', 'donald tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>sean: looking to the special edition of \"ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>FOXNEWSW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 01:00:00</td>\n",
       "      <td>2019-05-28 02:00:59</td>\n",
       "      <td>FOXNEWSW_20190528_010000_Hannity_Memorial_Day_...</td>\n",
       "      <td>['biden', 'russia', 'alec baldwin', 'donald tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>let's go to a flashback.</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>FOXNEWSW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 01:00:00</td>\n",
       "      <td>2019-05-28 02:00:59</td>\n",
       "      <td>FOXNEWSW_20190528_010000_Hannity_Memorial_Day_...</td>\n",
       "      <td>['biden', 'russia', 'alec baldwin', 'donald tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  \\\n",
       "0           0             0   \n",
       "1           1             1   \n",
       "2           2             2   \n",
       "3           3             4   \n",
       "4           4             5   \n",
       "\n",
       "                                            sentence  start_snip  end_snip  \\\n",
       "0                                              week.           0        60   \n",
       "1   tucker: tune in every night to the sworn enem...           0        60   \n",
       "2  have a great memorial day evening. see you tom...           0        60   \n",
       "3     sean: looking to the special edition of \"ha...           0        60   \n",
       "4                           let's go to a flashback.           0        60   \n",
       "\n",
       "  contributor   runtime           start_time            stop_time  \\\n",
       "0    FOXNEWSW  01:00:58  2019-05-28 01:00:00  2019-05-28 02:00:59   \n",
       "1    FOXNEWSW  01:00:58  2019-05-28 01:00:00  2019-05-28 02:00:59   \n",
       "2    FOXNEWSW  01:00:58  2019-05-28 01:00:00  2019-05-28 02:00:59   \n",
       "3    FOXNEWSW  01:00:58  2019-05-28 01:00:00  2019-05-28 02:00:59   \n",
       "4    FOXNEWSW  01:00:58  2019-05-28 01:00:00  2019-05-28 02:00:59   \n",
       "\n",
       "                                          identifier  \\\n",
       "0  FOXNEWSW_20190528_010000_Hannity_Memorial_Day_...   \n",
       "1  FOXNEWSW_20190528_010000_Hannity_Memorial_Day_...   \n",
       "2  FOXNEWSW_20190528_010000_Hannity_Memorial_Day_...   \n",
       "3  FOXNEWSW_20190528_010000_Hannity_Memorial_Day_...   \n",
       "4  FOXNEWSW_20190528_010000_Hannity_Memorial_Day_...   \n",
       "\n",
       "                                            subjects  \n",
       "0  ['biden', 'russia', 'alec baldwin', 'donald tr...  \n",
       "1  ['biden', 'russia', 'alec baldwin', 'donald tr...  \n",
       "2  ['biden', 'russia', 'alec baldwin', 'donald tr...  \n",
       "3  ['biden', 'russia', 'alec baldwin', 'donald tr...  \n",
       "4  ['biden', 'russia', 'alec baldwin', 'donald tr...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fox_df = pd.read_csv('../data/interim/fox-last-year-sent-comb.csv')\n",
    "fox_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fox_df = fox_df.drop(columns=['Unnamed: 0', 'Unnamed: 0.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2474856"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fox_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2474856 entries, 0 to 2474855\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Dtype         \n",
      "---  ------       -----         \n",
      " 0   sentence     object        \n",
      " 1   start_snip   int64         \n",
      " 2   end_snip     int64         \n",
      " 3   contributor  object        \n",
      " 4   runtime      object        \n",
      " 5   start_time   datetime64[ns]\n",
      " 6   stop_time    datetime64[ns]\n",
      " 7   identifier   object        \n",
      " 8   subjects     object        \n",
      "dtypes: datetime64[ns](2), int64(2), object(5)\n",
      "memory usage: 169.9+ MB\n"
     ]
    }
   ],
   "source": [
    "fox_df['start_time'] = pd.to_datetime(fox_df['start_time'])\n",
    "fox_df['stop_time'] = pd.to_datetime(fox_df['stop_time'])\n",
    "fox_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could',\n",
    "                           '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many',\n",
    "                           'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily',\n",
    "                           'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right',\n",
    "                           'line', 'even', 'also', 'may', 'take', 'come', 'hi', 'ha', 'le', 'u', 'wa', 'thi',\n",
    "                           'to', 'one'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sent(sentences):\n",
    "    for sent in sentences:\n",
    "        sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n",
    "        sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
    "        sent = re.sub(\"([\\d,\\,\\./!#$%&\\'\\\":;>\\?@\\[\\]`)(\\+])+\", \"\", sent) # remove digits and remove punctuation\n",
    "        sent = re.sub(\"([-])+\", \" \", sent)\n",
    "        yield(sent)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(strip_accents='unicode', stop_words=stop_words, \n",
    "                       min_df=2, max_df=0.3, ngram_range=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222589\n",
      "202614\n",
      "223310\n",
      "236944\n",
      "168128\n",
      "249392\n",
      "214486\n",
      "234296\n",
      "234291\n",
      "193337\n",
      "153342\n",
      "142127\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "start_date = fox_df['start_time'].min()\n",
    "month_df_list = []\n",
    "for i in range(12):\n",
    "    month_start = start_date + relativedelta(months=i)\n",
    "    month_end = month_start + relativedelta(months=1)\n",
    "    month_df = fox_df[(fox_df['start_time'] >= month_start) & (fox_df['start_time'] < month_end)]\n",
    "    print(len(month_df))\n",
    "    month_df_list.append(month_df)\n",
    "    \n",
    "print(len(month_df_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "count_dicts = []\n",
    "for i in range(12):\n",
    "    corpus = list(clean_sent(month_df_list[i].sentence.values.tolist()))\n",
    "    count_data = vect.fit_transform(corpus)\n",
    "    words = vect.get_feature_names()\n",
    "    total_counts = np.zeros(len(words))\n",
    "    for t in count_data:\n",
    "        total_counts+=t.toarray()[0]\n",
    "    count_dicts.append(dict(zip(words, total_counts)))\n",
    "    print(len(count_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a WordCloud object\n",
    "wordcloud = WordCloud(background_color=\"white\", max_words=5000, contour_width=3, contour_color='steelblue')\n",
    "for i in range(12):\n",
    "    # Generate a word cloud\n",
    "    wordcloud.generate_from_frequencies(count_dicts[i])\n",
    "    # Visualize the word cloud\n",
    "    wordcloud.to_image()\n",
    "    wordcloud.to_file('../reports/figures/month_' + str(i) + 'fox.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    df = pd.DataFrame(count_dicts[i], index=[0])\n",
    "    df.to_csv(r'../reports/fox_month_' + str(i) + 'word_frequencies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
