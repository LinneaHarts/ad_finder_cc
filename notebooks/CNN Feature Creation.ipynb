{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Make smaller dataset with full shows\n",
    "2. Run Kmeans clustering\n",
    "3. Make model based on Kmeans clustering\n",
    "4. Run model on snippets\n",
    "5. Run LDA\n",
    "6. Identify nearby words\n",
    "7. Do hand-coding\n",
    "8. Do statistical analysis on added features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import word_tokenize  \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNNW_20190528_170000_CNN_Right_Now_With_Briann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNNW_20190528_140000_CNN_Newsroom_with_Poppy_H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNNW_20190528_160000_Inside_Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNNW_20190528_050000_CNN_Special_Report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNNW_20190528_120000_New_Day_With_Alisyn_Camer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          identifier\n",
       "0  CNNW_20190528_170000_CNN_Right_Now_With_Briann...\n",
       "1  CNNW_20190528_140000_CNN_Newsroom_with_Poppy_H...\n",
       "2               CNNW_20190528_160000_Inside_Politics\n",
       "3            CNNW_20190528_050000_CNN_Special_Report\n",
       "4  CNNW_20190528_120000_New_Day_With_Alisyn_Camer..."
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_shows = pd.read_csv('../data/raw/search-cnn-last-year.csv')\n",
    "cnn_shows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_shows, _ = train_test_split(cnn_shows, test_size=0.9, random_state=18)\n",
    "len(cnn_shows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3460457"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_df = pd.read_csv('../data/interim/cnn-last-year-sent-comb.csv').drop(columns=['Unnamed: 0', \n",
    "                                                 'Unnamed: 0.1',\n",
    "                                                'Unnamed: 0.1.1']).dropna()\n",
    "len(cnn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334992"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get only cnn shows from show-based train_test_split\n",
    "cnn_df = cnn_df.set_index('identifier').join(cnn_shows.set_index('identifier'), on='identifier', how='inner')\n",
    "len(cnn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>sentence</th>\n",
       "      <th>start_snip</th>\n",
       "      <th>end_snip</th>\n",
       "      <th>contributor</th>\n",
       "      <th>runtime</th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>subjects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>now the fastest, most reliable internet can he...</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>that's simple, easy, awesome.</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>taxi!</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>should i have stopped her?</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>save hundreds of dollars a year when you get i...</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               identifier  \\\n",
       "0  CNNW_20190528_060000_CNN_Newsroom_Live   \n",
       "1  CNNW_20190528_060000_CNN_Newsroom_Live   \n",
       "2  CNNW_20190528_060000_CNN_Newsroom_Live   \n",
       "3  CNNW_20190528_060000_CNN_Newsroom_Live   \n",
       "4  CNNW_20190528_060000_CNN_Newsroom_Live   \n",
       "\n",
       "                                            sentence  start_snip  end_snip  \\\n",
       "0  now the fastest, most reliable internet can he...           0        60   \n",
       "1                      that's simple, easy, awesome.           0        60   \n",
       "2                                              taxi!           0        60   \n",
       "3                         should i have stopped her?           0        60   \n",
       "4  save hundreds of dollars a year when you get i...           0        60   \n",
       "\n",
       "  contributor   runtime           start_time            stop_time  \\\n",
       "0        CNNW  01:00:58  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "1        CNNW  01:00:58  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "2        CNNW  01:00:58  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "3        CNNW  01:00:58  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "4        CNNW  01:00:58  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "\n",
       "                                            subjects  \n",
       "0  ['trump', 'north korea', 'japan', 'rosemary', ...  \n",
       "1  ['trump', 'north korea', 'japan', 'rosemary', ...  \n",
       "2  ['trump', 'north korea', 'japan', 'rosemary', ...  \n",
       "3  ['trump', 'north korea', 'japan', 'rosemary', ...  \n",
       "4  ['trump', 'north korea', 'japan', 'rosemary', ...  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_df = cnn_df.reset_index()\n",
    "cnn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 334992 entries, 0 to 334991\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   identifier   334992 non-null  object\n",
      " 1   sentence     334992 non-null  object\n",
      " 2   start_snip   334992 non-null  int64 \n",
      " 3   end_snip     334992 non-null  int64 \n",
      " 4   contributor  334992 non-null  object\n",
      " 5   runtime      334992 non-null  object\n",
      " 6   start_time   334992 non-null  object\n",
      " 7   stop_time    334992 non-null  object\n",
      " 8   subjects     334992 non-null  object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 23.0+ MB\n"
     ]
    }
   ],
   "source": [
    "cnn_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Kmeans Clustering ##\n",
    "\n",
    "Run Kmeans clustering on sentences and determine which clusters are ads, which are news, and which are mixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could',\n",
    "                           '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many',\n",
    "                           'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily',\n",
    "                           'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right',\n",
    "                           'line', 'even', 'also', 'may', 'take', 'come', 'hi', 'ha', 'le', 'u', 'wa', 'thi',\n",
    "                           'to', 'one'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sent(sentences):\n",
    "    for sent in sentences:\n",
    "        sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n",
    "        sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
    "        sent = re.sub(\"([\\d,\\,\\./!#$%&\\'\\\":;>\\?@\\[\\]`)(\\+])+\", \"\", sent) # remove digits and remove punctuation\n",
    "        sent = re.sub(\"([-])+\", \" \", sent)\n",
    "        yield(sent)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['now the fastest most reliable internet can help you save on your wireless bill',\n",
       " 'thats simple easy awesome',\n",
       " 'taxi',\n",
       " 'should i have stopped her',\n",
       " 'save hundreds of dollars a year when you get internet and mobile together']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = list(clean_sent(cnn_df.sentence.values.tolist()))\n",
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatize before vectorizing\n",
    "\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
    "\n",
    "vect = TfidfVectorizer(tokenizer=LemmaTokenizer(), strip_accents='unicode', stop_words='english', \n",
    "                       min_df=2, max_df=0.3, ngram_range=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['now the fastest most reliable internet can help you save on your wireless bill',\n",
       " 'thats simple easy awesome',\n",
       " 'taxi',\n",
       " 'should i have stopped her',\n",
       " 'save hundreds of dollars a year when you get internet and mobile together']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = list(clean_sent(cnn_df.sentence.values.tolist()))\n",
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\envs\\ad-finder-cc\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['aa aa',\n",
       " 'aa aye',\n",
       " 'aa battery',\n",
       " 'aag best',\n",
       " 'aag introducing',\n",
       " 'aag trust',\n",
       " 'aag working',\n",
       " 'aags free',\n",
       " 'aags new',\n",
       " 'aan estimated',\n",
       " 'aaron burnett',\n",
       " 'aaron dean',\n",
       " 'aaron zebly',\n",
       " 'aarp auto',\n",
       " 'aarp endorsement',\n",
       " 'aarp ha',\n",
       " 'aarp high',\n",
       " 'aarp medicare',\n",
       " 'aarp meet',\n",
       " 'aarp member',\n",
       " 'aarp thats',\n",
       " 'ab ab',\n",
       " 'aba today',\n",
       " 'abaco bahamas',\n",
       " 'abaco grand',\n",
       " 'abaco island',\n",
       " 'abandon chair',\n",
       " 'abandon trump',\n",
       " 'abandoned abused',\n",
       " 'abandoned ally',\n",
       " 'abandoned effort',\n",
       " 'abandoned house',\n",
       " 'abandoned president',\n",
       " 'abandoned turned',\n",
       " 'abandoning ally',\n",
       " 'abandonment kurd',\n",
       " 'abbe confidentth',\n",
       " 'abbott getting',\n",
       " 'abbott helping',\n",
       " 'abbott technology',\n",
       " 'abbott test',\n",
       " 'abbvie able',\n",
       " 'abby philip',\n",
       " 'abby phillip',\n",
       " 'abby phillips',\n",
       " 'abby thank',\n",
       " 'abby u',\n",
       " 'abby week',\n",
       " 'abc didnt',\n",
       " 'abc direction',\n",
       " 'abc executive',\n",
       " 'abc faith',\n",
       " 'abc ha',\n",
       " 'abc happy',\n",
       " 'abc monday',\n",
       " 'abc news',\n",
       " 'abc newswashington',\n",
       " 'abc wa',\n",
       " 'abc wanted',\n",
       " 'abc washington',\n",
       " 'abcwashington post',\n",
       " 'abdication responsibility',\n",
       " 'abdomen allowed',\n",
       " 'abdomen pain',\n",
       " 'abdominal pain',\n",
       " 'abdominal shoulder',\n",
       " 'abe ha',\n",
       " 'abe japan',\n",
       " 'abe wa',\n",
       " 'abfrankly youre',\n",
       " 'abide look',\n",
       " 'abide rule',\n",
       " 'abide subpoena',\n",
       " 'abiding citizen',\n",
       " 'abiding rule',\n",
       " 'abiding social',\n",
       " 'abigail disney',\n",
       " 'abigail spam',\n",
       " 'ability ask',\n",
       " 'ability beat',\n",
       " 'ability buy',\n",
       " 'ability carry',\n",
       " 'ability claim',\n",
       " 'ability conduct',\n",
       " 'ability continue',\n",
       " 'ability cross',\n",
       " 'ability easily',\n",
       " 'ability empathize',\n",
       " 'ability evidence',\n",
       " 'ability execute',\n",
       " 'ability exercise',\n",
       " 'ability fight',\n",
       " 'ability good',\n",
       " 'ability hand',\n",
       " 'ability handle',\n",
       " 'ability hold',\n",
       " 'ability house',\n",
       " 'ability iranian',\n",
       " 'ability label',\n",
       " 'ability lead',\n",
       " 'ability listen',\n",
       " 'ability make',\n",
       " 'ability negotiate',\n",
       " 'ability preserve',\n",
       " 'ability president',\n",
       " 'ability pull',\n",
       " 'ability pump',\n",
       " 'ability purchase',\n",
       " 'ability question',\n",
       " 'ability raise',\n",
       " 'ability reach',\n",
       " 'ability say',\n",
       " 'ability state',\n",
       " 'ability talk',\n",
       " 'ability test',\n",
       " 'ability testing',\n",
       " 'ability treat',\n",
       " 'ability trust',\n",
       " 'ability u',\n",
       " 'ability united',\n",
       " 'ability use',\n",
       " 'ability virus',\n",
       " 'ability vote',\n",
       " 'ability work',\n",
       " 'ability write',\n",
       " 'abject failure',\n",
       " 'able able',\n",
       " 'able accept',\n",
       " 'able access',\n",
       " 'able accommodate',\n",
       " 'able account',\n",
       " 'able accumulate',\n",
       " 'able achieve',\n",
       " 'able acquire',\n",
       " 'able act',\n",
       " 'able action',\n",
       " 'able actually',\n",
       " 'able address',\n",
       " 'able adjudicate',\n",
       " 'able admit',\n",
       " 'able afford',\n",
       " 'able affordable',\n",
       " 'able answer',\n",
       " 'able articulate',\n",
       " 'able ask',\n",
       " 'able attend',\n",
       " 'able avoid',\n",
       " 'able away',\n",
       " 'able believe',\n",
       " 'able body',\n",
       " 'able breathe',\n",
       " 'able bring',\n",
       " 'able build',\n",
       " 'able business',\n",
       " 'able buy',\n",
       " 'able calm',\n",
       " 'able capitalize',\n",
       " 'able care',\n",
       " 'able carry',\n",
       " 'able celebrate',\n",
       " 'able change',\n",
       " 'able cherry',\n",
       " 'able city',\n",
       " 'able claim',\n",
       " 'able clear',\n",
       " 'able coalesce',\n",
       " 'able come',\n",
       " 'able communicate',\n",
       " 'able compete',\n",
       " 'able conduct',\n",
       " 'able confirm',\n",
       " 'able connect',\n",
       " 'able contain',\n",
       " 'able continue',\n",
       " 'able control',\n",
       " 'able convince',\n",
       " 'able cross',\n",
       " 'able deal',\n",
       " 'able debate',\n",
       " 'able declare',\n",
       " 'able defeat',\n",
       " 'able defend',\n",
       " 'able deliver',\n",
       " 'able detect',\n",
       " 'able determine',\n",
       " 'able develop',\n",
       " 'able different',\n",
       " 'able discover',\n",
       " 'able doctor',\n",
       " 'able document',\n",
       " 'able doing',\n",
       " 'able dont',\n",
       " 'able drive',\n",
       " 'able email',\n",
       " 'able end',\n",
       " 'able engage',\n",
       " 'able enter',\n",
       " 'able entire',\n",
       " 'able escape',\n",
       " 'able establish',\n",
       " 'able exercise',\n",
       " 'able exert',\n",
       " 'able expand',\n",
       " 'able explain',\n",
       " 'able fight',\n",
       " 'able figure',\n",
       " 'able fly',\n",
       " 'able folk',\n",
       " 'able follow',\n",
       " 'able form',\n",
       " 'able forward',\n",
       " 'able free',\n",
       " 'able friend',\n",
       " 'able fully',\n",
       " 'able gain',\n",
       " 'able gather',\n",
       " 'able ha',\n",
       " 'able hand',\n",
       " 'able handle',\n",
       " 'able head',\n",
       " 'able health',\n",
       " 'able hear',\n",
       " 'able help',\n",
       " 'able hold',\n",
       " 'able home',\n",
       " 'able hospital',\n",
       " 'able house',\n",
       " 'able housing',\n",
       " 'able identify',\n",
       " 'able improve',\n",
       " 'able information',\n",
       " 'able introduce',\n",
       " 'able invest',\n",
       " 'able island',\n",
       " 'able isolate',\n",
       " 'able job',\n",
       " 'able kill',\n",
       " 'able kind',\n",
       " 'able know',\n",
       " 'able learn',\n",
       " 'able leave',\n",
       " 'able legal',\n",
       " 'able listen',\n",
       " 'able little',\n",
       " 'able live',\n",
       " 'able locate',\n",
       " 'able look',\n",
       " 'able lot',\n",
       " 'able make',\n",
       " 'able meet',\n",
       " 'able message',\n",
       " 'able monitor',\n",
       " 'able mount',\n",
       " 'able negotiate',\n",
       " 'able offer',\n",
       " 'able office',\n",
       " 'able open',\n",
       " 'able opportunity',\n",
       " 'able outdivide',\n",
       " 'able outside',\n",
       " 'able participate',\n",
       " 'able pas',\n",
       " 'able past',\n",
       " 'able patientsf',\n",
       " 'able pay',\n",
       " 'able people',\n",
       " 'able perform',\n",
       " 'able persuade',\n",
       " 'able place',\n",
       " 'able play',\n",
       " 'able point',\n",
       " 'able portray',\n",
       " 'able present',\n",
       " 'able president',\n",
       " 'able press',\n",
       " 'able prevent',\n",
       " 'able process',\n",
       " 'able properly',\n",
       " 'able protect',\n",
       " 'able prove',\n",
       " 'able provide',\n",
       " 'able pull',\n",
       " 'able raise',\n",
       " 'able reach',\n",
       " 'able read',\n",
       " 'able really',\n",
       " 'able reconstruct',\n",
       " 'able recover',\n",
       " 'able relate',\n",
       " 'able remain',\n",
       " 'able rescue',\n",
       " 'able resist',\n",
       " 'able respond',\n",
       " 'able restore',\n",
       " 'able retire',\n",
       " 'able return',\n",
       " 'able reveal',\n",
       " 'able rule',\n",
       " 'able run',\n",
       " 'able safely',\n",
       " 'able save',\n",
       " 'able say',\n",
       " 'able school',\n",
       " 'able screen',\n",
       " 'able seal',\n",
       " 'able secure',\n",
       " 'able self',\n",
       " 'able sell',\n",
       " 'able send',\n",
       " 'able sent',\n",
       " 'able serve',\n",
       " 'able set',\n",
       " 'able shake',\n",
       " 'able share',\n",
       " 'able shoot',\n",
       " 'able smile',\n",
       " 'able social',\n",
       " 'able soon',\n",
       " 'able sort',\n",
       " 'able spar',\n",
       " 'able speak',\n",
       " 'able spend',\n",
       " 'able spread',\n",
       " 'able stand',\n",
       " 'able start',\n",
       " 'able stay',\n",
       " 'able stick',\n",
       " 'able stop',\n",
       " 'able support',\n",
       " 'able survey',\n",
       " 'able survive',\n",
       " 'able talk',\n",
       " 'able television',\n",
       " 'able tell',\n",
       " 'able test',\n",
       " 'able testify',\n",
       " 'able testing',\n",
       " 'able text',\n",
       " 'able thing',\n",
       " 'able think',\n",
       " 'able time',\n",
       " 'able touch',\n",
       " 'able tour',\n",
       " 'able trace',\n",
       " 'able track',\n",
       " 'able train',\n",
       " 'able treat',\n",
       " 'able trust',\n",
       " 'able turn',\n",
       " 'able u',\n",
       " 'able understand',\n",
       " 'able united',\n",
       " 'able use',\n",
       " 'able used',\n",
       " 'able utilize',\n",
       " 'able verify',\n",
       " 'able view',\n",
       " 'able visit',\n",
       " 'able vote',\n",
       " 'able wa',\n",
       " 'able walk',\n",
       " 'able want',\n",
       " 'able watch',\n",
       " 'able wear',\n",
       " 'able week',\n",
       " 'able white',\n",
       " 'able win',\n",
       " 'able withhold',\n",
       " 'able withstand',\n",
       " 'able witness',\n",
       " 'able work',\n",
       " 'able wrap',\n",
       " 'able youre',\n",
       " 'abnormal bleeding',\n",
       " 'abnormal heartbeat',\n",
       " 'abnormality blindness',\n",
       " 'abnormality liver',\n",
       " 'abnormally high',\n",
       " 'aboard air',\n",
       " 'aboard conception',\n",
       " 'aboard crew',\n",
       " 'aboard cruise',\n",
       " 'aboard nile',\n",
       " 'aboard roosevelt',\n",
       " 'aboard vessel',\n",
       " 'abolish protection',\n",
       " 'abollishing hyde',\n",
       " 'abortion case',\n",
       " 'abortion debate',\n",
       " 'abortion federal',\n",
       " 'abortion funding',\n",
       " 'abortion immigration',\n",
       " 'abortion law',\n",
       " 'abortion opponent',\n",
       " 'abortion right',\n",
       " 'abortion state',\n",
       " 'abraham lincoln',\n",
       " 'abreast dont',\n",
       " 'abreva act',\n",
       " 'abreva cany',\n",
       " 'abreva start',\n",
       " 'abroad hard',\n",
       " 'abroad home',\n",
       " 'abroad look',\n",
       " 'abroad time',\n",
       " 'abroad u',\n",
       " 'abrupt departure',\n",
       " 'abruptly dismissed',\n",
       " 'abruptly ended',\n",
       " 'abruptly ending',\n",
       " 'abruptly pulled',\n",
       " 'abruptly quit',\n",
       " 'absence strategy',\n",
       " 'absentee ballot',\n",
       " 'absentee voting',\n",
       " 'absolute best',\n",
       " 'absolute chaotic',\n",
       " 'absolute comey',\n",
       " 'absolute immunity',\n",
       " 'absolute level',\n",
       " 'absolute majority',\n",
       " 'absolute number',\n",
       " 'absolute power',\n",
       " 'absolute right',\n",
       " 'absolute worst',\n",
       " 'absolutely absurd',\n",
       " 'absolutely agree',\n",
       " 'absolutely anderson',\n",
       " 'absolutely bizarre',\n",
       " 'absolutely certain',\n",
       " 'absolutely chaotic',\n",
       " 'absolutely clear',\n",
       " 'absolutely come',\n",
       " 'absolutely correct',\n",
       " 'absolutely criminal',\n",
       " 'absolutely critical',\n",
       " 'absolutely determined',\n",
       " 'absolutely devastating',\n",
       " 'absolutely did',\n",
       " 'absolutely dissing',\n",
       " 'absolutely doe',\n",
       " 'absolutely doing',\n",
       " 'absolutely essential',\n",
       " 'absolutely evidence',\n",
       " 'absolutely false',\n",
       " 'absolutely going',\n",
       " 'absolutely ha',\n",
       " 'absolutely hated',\n",
       " 'absolutely idea',\n",
       " 'absolutely ill',\n",
       " 'absolutely im',\n",
       " 'absolutely immune',\n",
       " 'absolutely imperative',\n",
       " 'absolutely impossible',\n",
       " 'absolutely inaccurate',\n",
       " 'absolutely intelligently',\n",
       " 'absolutely issue',\n",
       " 'absolutely jim',\n",
       " 'absolutely know',\n",
       " 'absolutely love',\n",
       " 'absolutely ludicrous',\n",
       " 'absolutely matter',\n",
       " 'absolutely moving',\n",
       " 'absolutely necessary',\n",
       " 'absolutely need',\n",
       " 'absolutely outrageous',\n",
       " 'absolutely perfect',\n",
       " 'absolutely question',\n",
       " 'absolutely quid',\n",
       " 'absolutely reason',\n",
       " 'absolutely relationship',\n",
       " 'absolutely ridiculous',\n",
       " 'absolutely right',\n",
       " 'absolutely risk',\n",
       " 'absolutely say',\n",
       " 'absolutely sens',\n",
       " 'absolutely shocking',\n",
       " 'absolutely sign',\n",
       " 'absolutely stunning',\n",
       " 'absolutely terrified',\n",
       " 'absolutely thats',\n",
       " 'absolutely think',\n",
       " 'absolutely time',\n",
       " 'absolutely true',\n",
       " 'absolutely unprecedented',\n",
       " 'absolutely wa',\n",
       " 'absolutely washington',\n",
       " 'absolutely way',\n",
       " 'absolutely wrong',\n",
       " 'absorb channel',\n",
       " 'absorb going',\n",
       " 'absorbency trusted',\n",
       " 'absorbent core',\n",
       " 'absorbent leading',\n",
       " 'absorbs deep',\n",
       " 'absorbs dirt',\n",
       " 'absorbs quickly',\n",
       " 'absorbs x',\n",
       " 'absorption promote',\n",
       " 'absorption promoting',\n",
       " 'abstaining food',\n",
       " 'absurd notion',\n",
       " 'absurd position',\n",
       " 'abu bakr',\n",
       " 'abu dhabi',\n",
       " 'abundance caution',\n",
       " 'abundantly clear',\n",
       " 'abuse allegation',\n",
       " 'abuse case',\n",
       " 'abuse child',\n",
       " 'abuse domestic',\n",
       " 'abuse harassment',\n",
       " 'abuse issue',\n",
       " 'abuse neglect',\n",
       " 'abuse office',\n",
       " 'abuse online',\n",
       " 'abuse power',\n",
       " 'abuse public',\n",
       " 'abuse scandal',\n",
       " 'abuse trust',\n",
       " 'abuse violation',\n",
       " 'abuse wa',\n",
       " 'abused case',\n",
       " 'abused dozen',\n",
       " 'abused office',\n",
       " 'abused power',\n",
       " 'abusing child',\n",
       " 'abusing high',\n",
       " 'abusing office',\n",
       " 'abusing power',\n",
       " 'abusive destructive',\n",
       " 'abusive family',\n",
       " 'abusive power',\n",
       " 'abusive relationship',\n",
       " 'ac adult',\n",
       " 'ac anderson',\n",
       " 'ac help',\n",
       " 'ac le',\n",
       " 'ac lower',\n",
       " 'ac maintained',\n",
       " 'ac start',\n",
       " 'ac thompson',\n",
       " 'academic health',\n",
       " 'academy award',\n",
       " 'academy instead',\n",
       " 'academy like',\n",
       " 'academy pediatrics',\n",
       " 'academy science',\n",
       " 'academy standing',\n",
       " 'academy year',\n",
       " 'accelerate development',\n",
       " 'accept allergy',\n",
       " 'accept american',\n",
       " 'accept animal',\n",
       " 'accept answer',\n",
       " 'accept bribe',\n",
       " 'accept character',\n",
       " 'accept contract',\n",
       " 'accept easily',\n",
       " 'accept explanation',\n",
       " 'accept face',\n",
       " 'accept fact',\n",
       " 'accept fbi',\n",
       " 'accept foreign',\n",
       " 'accept frompt',\n",
       " 'accept help',\n",
       " 'accept house',\n",
       " 'accept incomplete',\n",
       " 'accept invitation',\n",
       " 'accept legitimacy',\n",
       " 'accept love',\n",
       " 'accept medicare',\n",
       " 'accept money',\n",
       " 'accept payment',\n",
       " 'accept president',\n",
       " 'accept reality',\n",
       " 'accept receive',\n",
       " 'accept responsibility',\n",
       " 'accept united',\n",
       " 'accept victory',\n",
       " 'acceptable answer',\n",
       " 'acceptable behavior',\n",
       " 'acceptance guaranteed',\n",
       " 'acceptance parkland',\n",
       " 'accepted ada',\n",
       " 'accepted place',\n",
       " 'accepted resignation',\n",
       " 'accepted responsibility',\n",
       " 'accepting donation',\n",
       " 'accepting foreign',\n",
       " 'accepts medicare',\n",
       " 'access affordable',\n",
       " 'access american',\n",
       " 'access best',\n",
       " 'access black',\n",
       " 'access care',\n",
       " 'access classified',\n",
       " 'access coach',\n",
       " 'access country',\n",
       " 'access coverage',\n",
       " 'access credit',\n",
       " 'access data',\n",
       " 'access denied',\n",
       " 'access doctor',\n",
       " 'access document',\n",
       " 'access education',\n",
       " 'access electricity',\n",
       " 'access expanded',\n",
       " 'access facility',\n",
       " 'access food',\n",
       " 'access g',\n",
       " 'access got',\n",
       " 'access government',\n",
       " 'access gun',\n",
       " 'access ha',\n",
       " 'access health',\n",
       " 'access healthcare',\n",
       " 'access help',\n",
       " 'access hollywood',\n",
       " 'access information',\n",
       " 'access intelligence',\n",
       " 'access internet',\n",
       " 'access island',\n",
       " 'access k',\n",
       " 'access kind',\n",
       " 'access life',\n",
       " 'access medium',\n",
       " 'access million',\n",
       " 'access official',\n",
       " 'access oil',\n",
       " 'access panel',\n",
       " 'access people',\n",
       " 'access platform',\n",
       " 'access point',\n",
       " 'access political',\n",
       " 'access power',\n",
       " 'access president',\n",
       " 'access quality',\n",
       " 'access research',\n",
       " 'access russian',\n",
       " 'access shower',\n",
       " 'access soap',\n",
       " 'access software',\n",
       " 'access t',\n",
       " 'access tax',\n",
       " 'access team',\n",
       " 'access test',\n",
       " 'access testing',\n",
       " 'access thats',\n",
       " 'access time',\n",
       " 'access transcript',\n",
       " 'access trump',\n",
       " 'access twitter',\n",
       " 'access unlimited',\n",
       " 'access video',\n",
       " 'access wall',\n",
       " 'access weapon',\n",
       " 'access weve',\n",
       " 'access white',\n",
       " 'accessed home',\n",
       " 'accessed ring',\n",
       " 'accessible affordable',\n",
       " 'accessible citizen',\n",
       " 'accessible time',\n",
       " 'accessing password',\n",
       " 'accessoriesphones mobile',\n",
       " 'accident big',\n",
       " 'accident brought',\n",
       " 'accident chernobyl',\n",
       " 'accident everybody',\n",
       " 'accident fault',\n",
       " 'accident forgiveness',\n",
       " 'accident grover',\n",
       " 'accident happen',\n",
       " 'accident happened',\n",
       " 'accident killed',\n",
       " 'accident site',\n",
       " 'accident wa',\n",
       " 'accidental player',\n",
       " 'accidentally shot',\n",
       " 'accidentally visiting',\n",
       " 'acco according',\n",
       " 'accommodation starting',\n",
       " 'accomplish goal',\n",
       " 'accomplish trying',\n",
       " 'accomplish want',\n",
       " 'accomplished thing',\n",
       " 'accomplished wa',\n",
       " 'accomplished yesterday',\n",
       " 'accordance constitution',\n",
       " 'according administration',\n",
       " 'according america',\n",
       " 'according american',\n",
       " 'according analysis',\n",
       " 'according arrest',\n",
       " 'according attorney',\n",
       " 'according authority',\n",
       " 'according cdc',\n",
       " 'according census',\n",
       " 'according christian',\n",
       " 'according church',\n",
       " 'according cnn',\n",
       " 'according cnns',\n",
       " 'according complaint',\n",
       " 'according conception',\n",
       " 'according constitution',\n",
       " 'according corrupt',\n",
       " 'according court',\n",
       " 'according cy',\n",
       " 'according data',\n",
       " 'according defense',\n",
       " 'according democrat',\n",
       " 'according democratic',\n",
       " 'according department',\n",
       " 'according document',\n",
       " 'according expert',\n",
       " 'according fbi',\n",
       " 'according federal',\n",
       " 'according forbes',\n",
       " 'according fox',\n",
       " 'according gospel',\n",
       " 'according governor',\n",
       " 'according health',\n",
       " 'according intelligence',\n",
       " 'according investigator',\n",
       " 'according iranian',\n",
       " 'according john',\n",
       " 'according judge',\n",
       " 'according latest',\n",
       " 'according law',\n",
       " 'according lawmaker',\n",
       " 'according lawsuit',\n",
       " 'according lawyer',\n",
       " 'according letter',\n",
       " 'according local',\n",
       " 'according mayor',\n",
       " 'according mueller',\n",
       " 'according multiple',\n",
       " 'according national',\n",
       " 'according new',\n",
       " 'according newly',\n",
       " 'according ntsb',\n",
       " 'according official',\n",
       " 'according pentagon',\n",
       " 'according people',\n",
       " 'according police',\n",
       " 'according politico',\n",
       " 'according poll',\n",
       " 'according post',\n",
       " 'according president',\n",
       " 'according press',\n",
       " 'according prosecutor',\n",
       " 'according recent',\n",
       " 'according report',\n",
       " 'according reporting',\n",
       " 'according republican',\n",
       " 'according research',\n",
       " 'according researcher',\n",
       " 'according royal',\n",
       " 'according rule',\n",
       " 'according russian',\n",
       " 'according scientist',\n",
       " 'according senior',\n",
       " 'according source',\n",
       " 'according spokesman',\n",
       " 'according state',\n",
       " 'according statement',\n",
       " 'according study',\n",
       " 'according supreme',\n",
       " 'according taylor',\n",
       " 'according testimony',\n",
       " 'according time',\n",
       " 'according transcript',\n",
       " 'according trump',\n",
       " 'according u',\n",
       " 'according wall',\n",
       " 'according washington',\n",
       " 'according white',\n",
       " 'according witness',\n",
       " 'account actually',\n",
       " 'account app',\n",
       " 'account came',\n",
       " 'account cash',\n",
       " 'account conversation',\n",
       " 'account death',\n",
       " 'account doesnt',\n",
       " 'account fee',\n",
       " 'account ha',\n",
       " 'account half',\n",
       " 'account happened',\n",
       " 'account hospital',\n",
       " 'account inside',\n",
       " 'account life',\n",
       " 'account look',\n",
       " 'account lot',\n",
       " 'account make',\n",
       " 'account minimum',\n",
       " 'account past',\n",
       " 'account plus',\n",
       " 'account republican',\n",
       " 'account say',\n",
       " 'account saying',\n",
       " 'account security',\n",
       " 'account state',\n",
       " 'account talk',\n",
       " 'account theyre',\n",
       " 'account today',\n",
       " 'account took',\n",
       " 'account virus',\n",
       " 'account wa',\n",
       " 'account world',\n",
       " 'account zero',\n",
       " 'accountability charter',\n",
       " 'accountability decision',\n",
       " 'accountability despite',\n",
       " 'accountability end',\n",
       " 'accountability justice',\n",
       " 'accountability office',\n",
       " 'accountability president',\n",
       " 'accountable action',\n",
       " 'accountable forward',\n",
       " 'accountable just',\n",
       " 'accountable law',\n",
       " 'accountable need',\n",
       " 'accountable think',\n",
       " 'accounting firm',\n",
       " 'accumulate delegate',\n",
       " 'accumulation day',\n",
       " 'accumulation possible',\n",
       " 'accuracy drawing',\n",
       " 'accuracy learning',\n",
       " 'accuracy memory',\n",
       " 'accuracy test',\n",
       " 'accurate fair',\n",
       " 'accurate hurricane',\n",
       " 'accurate information',\n",
       " 'accurate number',\n",
       " 'accurate pin',\n",
       " 'accurate representation',\n",
       " 'accurate state',\n",
       " 'accurate theyre',\n",
       " 'accurate wa',\n",
       " 'accusation exploiting',\n",
       " 'accusation joe',\n",
       " 'accusation president',\n",
       " 'accusation wa',\n",
       " 'accusation way',\n",
       " 'accuse biden',\n",
       " 'accuse democrat',\n",
       " 'accuse president',\n",
       " 'accuse woman',\n",
       " 'accused able',\n",
       " 'accused aggressive',\n",
       " 'accused attack',\n",
       " 'accused breaking',\n",
       " 'accused child',\n",
       " 'accused citizen',\n",
       " 'accused democrat',\n",
       " 'accused doing',\n",
       " 'accused driving',\n",
       " 'accused evidence',\n",
       " 'accused exploiting',\n",
       " 'accused funneling',\n",
       " 'accused going',\n",
       " 'accused having',\n",
       " 'accused impeachment',\n",
       " 'accused involved',\n",
       " 'accused killing',\n",
       " 'accused murder',\n",
       " 'accused murdering',\n",
       " 'accused paying',\n",
       " 'accused president',\n",
       " 'accused pursuing',\n",
       " 'accused rape',\n",
       " 'accused richard',\n",
       " 'accused sex',\n",
       " 'accused sexual',\n",
       " 'accused shooting',\n",
       " 'accused spencer',\n",
       " 'accused stabbing',\n",
       " 'accused stealing',\n",
       " 'accused tabloid',\n",
       " 'accused terrorist',\n",
       " 'accused threatening',\n",
       " 'accused trying',\n",
       " 'accused undermining',\n",
       " 'accused using',\n",
       " 'accused video',\n",
       " 'accused wrongdoing',\n",
       " 'accuser family',\n",
       " 'accuser ha',\n",
       " 'accuser say',\n",
       " 'accuses people',\n",
       " 'accusing biden',\n",
       " 'accusing democrat',\n",
       " 'accusing espionage',\n",
       " 'accusing google',\n",
       " 'accusing joe',\n",
       " 'accusing mr',\n",
       " 'accusing new',\n",
       " 'accusing opponent',\n",
       " 'accusing people',\n",
       " 'accusing president',\n",
       " 'accusing republican',\n",
       " 'accusing soft',\n",
       " 'accusing treason',\n",
       " 'accusing trump',\n",
       " 'accusing united',\n",
       " 'accusing white',\n",
       " 'ace arb',\n",
       " 'ace inhibitor',\n",
       " 'aceves family',\n",
       " 'ache cough',\n",
       " 'achievable reduced',\n",
       " 'achieve control',\n",
       " 'achieve dream',\n",
       " 'achieve ficial',\n",
       " 'achieve goal',\n",
       " 'achieve investor',\n",
       " 'achieve long',\n",
       " 'achieve people',\n",
       " 'achieve personally',\n",
       " 'achieve political',\n",
       " 'achieve president',\n",
       " 'achieved bring',\n",
       " 'achieved clearer',\n",
       " 'achieved great',\n",
       " 'achieved new',\n",
       " 'achieved objective',\n",
       " 'achieved remission',\n",
       " 'achievement award',\n",
       " 'achievement modern',\n",
       " 'aching stuffy',\n",
       " 'acid buildup',\n",
       " 'acid liver',\n",
       " 'acid moisturizer',\n",
       " 'acid plump',\n",
       " 'acid production',\n",
       " 'acid reflux',\n",
       " 'acid serum',\n",
       " 'acid start',\n",
       " 'acidic theyre',\n",
       " 'acidon little',\n",
       " 'acknowledge fact',\n",
       " 'acknowledge inside',\n",
       " 'acknowledge president',\n",
       " 'acknowledge quid',\n",
       " 'acknowledge reality',\n",
       " 'acknowledge russian',\n",
       " 'acknowledge wa',\n",
       " 'acknowledge wrong',\n",
       " 'acknowledged mistake',\n",
       " 'acknowledged responsibility',\n",
       " 'acknowledged south',\n",
       " 'acknowledged wa',\n",
       " 'acknowledging real',\n",
       " 'acknowledging tweet',\n",
       " 'acknowledgment quid',\n",
       " 'aclu ha',\n",
       " 'acosta came',\n",
       " 'acosta cnn',\n",
       " 'acosta ha',\n",
       " 'acosta join',\n",
       " 'acosta joining',\n",
       " 'acosta just',\n",
       " 'acosta live',\n",
       " 'acosta said',\n",
       " 'acosta thank',\n",
       " 'acosta time',\n",
       " 'acosta wa',\n",
       " 'acosta white',\n",
       " 'acostas report',\n",
       " 'acostas reporting',\n",
       " 'acqua di',\n",
       " 'acqua panna',\n",
       " 'acquire property',\n",
       " 'acquired infection',\n",
       " 'acquit president',\n",
       " 'acquittal conviction',\n",
       " 'acquittal president',\n",
       " 'acquittal senate',\n",
       " 'acquittal think',\n",
       " 'acquittal virtually',\n",
       " 'acquittal vote',\n",
       " 'acquittal week',\n",
       " 'acquitted charge',\n",
       " 'acquitted fact',\n",
       " 'acquitted impeachment',\n",
       " 'acquitted later',\n",
       " 'acquitted premeditated',\n",
       " 'acquitted president',\n",
       " 'acquitted senate',\n",
       " 'acquitted trump',\n",
       " 'acquitted wa',\n",
       " 'acquitted war',\n",
       " 'acquitted worst',\n",
       " 'acquitting president',\n",
       " 'acre burned',\n",
       " 'acre destroyed',\n",
       " 'acre scorched',\n",
       " ...]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_bow = vect.fit_transform(corpus)\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=75, random_state=18)\n",
    "results = kmeans.fit_predict(cnn_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      " operation place\n",
      " caucus dont\n",
      " vote caucus\n",
      " place drive\n",
      " 速 vaccine\n",
      " gupta talk\n",
      " gust high\n",
      " gust causing\n",
      " gurgen joe\n",
      " gupta u\n",
      "\n",
      "Cluster 1:\n",
      " president trump\n",
      " dont know\n",
      " united state\n",
      " new york\n",
      " donald trump\n",
      " joe biden\n",
      " im going\n",
      " bernie sander\n",
      " breaking news\n",
      " vice president\n",
      "\n",
      "Cluster 2:\n",
      " cut half\n",
      " cost shipping\n",
      " shipping cut\n",
      " gupta professor\n",
      " gust high\n",
      " gust causing\n",
      " gurgen joe\n",
      " gupta u\n",
      " gupta thanks\n",
      " gupta thank\n",
      "\n",
      "Cluster 3:\n",
      " andrew yang\n",
      " candidate andrew\n",
      " presidential candidate\n",
      " businessman andrew\n",
      " yang thanks\n",
      " democratic presidential\n",
      " yang u\n",
      " yang wife\n",
      " entrepreneur democratic\n",
      " joining entrepreneur\n",
      "\n",
      "Cluster 4:\n",
      " year old\n",
      " wa year\n",
      " old wa\n",
      " wa accident\n",
      " old year\n",
      " old want\n",
      " old girl\n",
      " buy car\n",
      " want buy\n",
      " old daughter\n",
      "\n",
      "Cluster 5:\n",
      " wa missing\n",
      " realized wa\n",
      " ulcerative colitising\n",
      " colitising realized\n",
      " severe ulcerative\n",
      " moderate severe\n",
      " roof wa\n",
      " night wa\n",
      " gupta professor\n",
      " gust causing\n",
      "\n",
      "Cluster 6:\n",
      " wa executed\n",
      " really way\n",
      " adult life\n",
      " morning wa\n",
      " way wa\n",
      " 速 vaccine\n",
      " gupta perspective\n",
      " gurgen joe\n",
      " gupta u\n",
      " gupta thanks\n",
      "\n",
      "Cluster 7:\n",
      " promise better\n",
      " really promise\n",
      " better sleep\n",
      " 速 vaccine\n",
      " gupta just\n",
      " gurgen joe\n",
      " gupta u\n",
      " gupta thanks\n",
      " gupta thank\n",
      " gupta talk\n",
      "\n",
      "Cluster 8:\n",
      " im speechless\n",
      " ha im\n",
      " today ha\n",
      " gupta talk\n",
      " gust hurricane\n",
      " gust high\n",
      " gust causing\n",
      " gurgen joe\n",
      " gupta u\n",
      " gupta thanks\n",
      "\n",
      "Cluster 9:\n",
      " giuliani tell\n",
      " cnn aware\n",
      " tell cnn\n",
      " rudy giuliani\n",
      " 速 vaccine\n",
      " gupta talk\n",
      " gust causing\n",
      " gurgen joe\n",
      " gupta u\n",
      " gupta thanks\n",
      "\n",
      "Cluster 10:\n",
      " thank joining\n",
      " joining u\n",
      " congressman thank\n",
      " u morning\n",
      " inside politics\n",
      " joining today\n",
      " u new\n",
      " u inside\n",
      " senator thank\n",
      " u today\n",
      "\n",
      "Cluster 11:\n",
      " karaoke later\n",
      " u karaoke\n",
      " joining u\n",
      " gust high\n",
      " gurgen joe\n",
      " gupta u\n",
      " gupta thanks\n",
      " gupta thank\n",
      " gupta talk\n",
      " gupta professor\n",
      "\n",
      "Cluster 12:\n",
      " appreciate time\n",
      " time tonight\n",
      " really appreciate\n",
      " time sir\n",
      " congressman appreciate\n",
      " governor appreciate\n",
      " panetta appreciate\n",
      " secretary panetta\n",
      " thank appreciate\n",
      " senator sander\n",
      "\n",
      "Cluster 13:\n",
      " way stubborn\n",
      " fat just\n",
      " stubborn fat\n",
      " wont away\n",
      " life way\n",
      " just wont\n",
      " gust hurricane\n",
      " gust high\n",
      " gust causing\n",
      " gurgen joe\n",
      "\n",
      "Cluster 14:\n",
      " looking good\n",
      " good patrick\n",
      " good south\n",
      " thing looking\n",
      " youre looking\n",
      " number looking\n",
      " think looking\n",
      " good man\n",
      " add looking\n",
      " good way\n",
      "\n",
      "Cluster 15:\n",
      " ah relax\n",
      " 速 vaccine\n",
      " gupta professor\n",
      " gust high\n",
      " gust causing\n",
      " gurgen joe\n",
      " gupta u\n",
      " gupta thanks\n",
      " gupta thank\n",
      " gupta talk\n",
      "\n",
      "Cluster 16:\n",
      " join u\n",
      " u live\n",
      " fighting whats\n",
      " u fighting\n",
      " whats right\n",
      " acosta join\n",
      " u switch\n",
      " jim acosta\n",
      " u capitol\n",
      " white house\n",
      "\n",
      "Cluster 17:\n",
      " fight cancer\n",
      " world fight\n",
      " changed world\n",
      " gupta thanks\n",
      " gust moving\n",
      " gust mile\n",
      " gust hurricane\n",
      " gust high\n",
      " gust causing\n",
      " gurgen joe\n",
      "\n",
      "Cluster 18:\n",
      " thing learn\n",
      " learn pretty\n",
      " pretty quickly\n",
      " lot learn\n",
      " quickly lot\n",
      " quickly iran\n",
      " pretty small\n",
      " gray area\n",
      " 速 vaccine\n",
      " gupta talk\n",
      "\n",
      "Cluster 19:\n",
      " camera figure\n",
      " african american\n",
      " 速 vaccine\n",
      " gupta thank\n",
      " gust mile\n",
      " gust hurricane\n",
      " gust high\n",
      " gust causing\n",
      " gurgen joe\n",
      " gupta u\n",
      "\n",
      "Cluster 20:\n",
      " plus surprise\n",
      " gupta professor\n",
      " gust hurricane\n",
      " gust high\n",
      " gust causing\n",
      " gurgen joe\n",
      " gupta u\n",
      " gupta thanks\n",
      " gupta thank\n",
      " gupta talk\n",
      "\n",
      "Cluster 21:\n",
      " dog wrong\n",
      " treat dog\n",
      " start better\n",
      " better thats\n",
      " way treat\n",
      " thats way\n",
      " gust mile\n",
      " gust hurricane\n",
      " gust high\n",
      " gust causing\n",
      "\n",
      "Cluster 22:\n",
      " price starting\n",
      " starting line\n",
      " best plan\n",
      " network best\n",
      " att ha\n",
      " ha america\n",
      " best price\n",
      " ok att\n",
      " plan best\n",
      " best network\n",
      "\n",
      "Cluster 23:\n",
      " delivery experience\n",
      " experience count\n",
      " 速 vaccine\n",
      " gupta professor\n",
      " gust high\n",
      " gust causing\n",
      " gurgen joe\n",
      " gupta u\n",
      " gupta thanks\n",
      " gupta thank\n",
      "\n",
      "Cluster 24:\n",
      " talk doctor\n",
      " doctor chantix\n",
      " doctor mavyret\n",
      " doctor aimovig\n",
      " pharmacist today\n",
      " doctor pharmacist\n",
      " doctor dupixent\n",
      " doctor today\n",
      " needed talk\n",
      " knew needed\n",
      "\n",
      "Cluster 25:\n",
      " social distancing\n",
      " distancing guideline\n",
      " distancing measure\n",
      " practicing social\n",
      " distancing rule\n",
      " doing social\n",
      " wearing mask\n",
      " distancing restriction\n",
      " distancing important\n",
      " mean social\n",
      "\n",
      "Cluster 26:\n",
      " ill tell\n",
      " tell important\n",
      " know medicare\n",
      " tell right\n",
      " thing know\n",
      " important thing\n",
      " tell im\n",
      " tell break\n",
      " minute ill\n",
      " tell thing\n",
      "\n",
      "Cluster 27:\n",
      " xfinity store\n",
      " store today\n",
      " shop discover\n",
      " ask shop\n",
      " come ask\n",
      " local xfinity\n",
      " discover xfinity\n",
      " discover local\n",
      " gupta joining\n",
      " gupta thank\n",
      "\n",
      "Cluster 28:\n",
      " im yoevery\n",
      " yoevery moven\n",
      " moven law\n",
      " question im\n",
      " like question\n",
      " like smell\n",
      " smell laugh\n",
      " laugh like\n",
      " yes men\n",
      " men like\n",
      "\n",
      "Cluster 29:\n",
      " coverage kid\n",
      " dropped record\n",
      " kid upgraded\n",
      " rate dropped\n",
      " care infant\n",
      " upgraded pediatric\n",
      " pediatric care\n",
      " helped expand\n",
      " expand health\n",
      " health coverage\n",
      "\n",
      "Cluster 30:\n",
      " little bit\n",
      " just little\n",
      " think little\n",
      " talk little\n",
      " wa little\n",
      " bit different\n",
      " ill little\n",
      " bit like\n",
      " bit better\n",
      " thats little\n",
      "\n",
      "Cluster 31:\n",
      " let send\n",
      " send message\n",
      " fred let\n",
      " message american\n",
      " american people\n",
      " 速 vaccine\n",
      " gust high\n",
      " gust causing\n",
      " gurgen joe\n",
      " gupta u\n",
      "\n",
      "Cluster 32:\n",
      " just broke\n",
      " gray area\n",
      " area just\n",
      " broke news\n",
      " news trump\n",
      " broke know\n",
      " trump campaign\n",
      " know just\n",
      " 速 vaccine\n",
      " gust hurricane\n",
      "\n",
      "Cluster 33:\n",
      " meat cheese\n",
      " cheese nut\n",
      " mix meat\n",
      " gust wind\n",
      " gust mile\n",
      " gust hurricane\n",
      " gust high\n",
      " gust causing\n",
      " gurgen joe\n",
      " gupta u\n",
      "\n",
      "Cluster 34:\n",
      " early start\n",
      " welcome early\n",
      " im dave\n",
      " dave briggs\n",
      " start continues\n",
      " continues right\n",
      " viewer early\n",
      " u viewer\n",
      " morning welcome\n",
      " good morning\n",
      "\n",
      "Cluster 35:\n",
      " state world\n",
      " welcome viewer\n",
      " viewer united\n",
      " united state\n",
      " want welcome\n",
      " hello welcome\n",
      " welcome united\n",
      " viewer joining\n",
      " u united\n",
      " world im\n",
      "\n",
      "Cluster 36:\n",
      " need place\n",
      " expedia ha\n",
      " ha need\n",
      " gust mile\n",
      " gust high\n",
      " gust causing\n",
      " gurgen joe\n",
      " gupta u\n",
      " gupta thanks\n",
      " gupta thank\n",
      "\n",
      "Cluster 37:\n",
      " whoo hoo\n",
      " 速 vaccine\n",
      " gust wind\n",
      " gust mile\n",
      " gust hurricane\n",
      " gust high\n",
      " gust causing\n",
      " gurgen joe\n",
      " gupta u\n",
      " gupta thanks\n",
      "\n",
      "Cluster 38:\n",
      " topping pizza\n",
      " pizza just\n",
      " medium topping\n",
      " day marcos\n",
      " marcos medium\n",
      " day medium\n",
      " gupta perspective\n",
      " gust causing\n",
      " gurgen joe\n",
      " gupta u\n",
      "\n",
      "Cluster 39:\n",
      " otezla cream\n",
      " gupta professor\n",
      " gust hurricane\n",
      " gust high\n",
      " gust causing\n",
      " gurgen joe\n",
      " gupta u\n",
      " gupta thanks\n",
      " gupta thank\n",
      " gupta talk\n",
      "\n",
      "Cluster 40:\n",
      " brooke baldwin\n",
      " im brooke\n",
      " cnn im\n",
      " watching cnn\n",
      " youre watching\n",
      " baldwin thank\n",
      " hi im\n",
      " hello im\n",
      " lead start\n",
      " afternoon im\n",
      "\n",
      "Cluster 41:\n",
      " dont think\n",
      " think thats\n",
      " think going\n",
      " think wa\n",
      " just dont\n",
      " think need\n",
      " think president\n",
      " think know\n",
      " think theyre\n",
      " think im\n",
      "\n",
      "Cluster 42:\n",
      " like coffee\n",
      " exactly like\n",
      " 速 vaccine\n",
      " gupta perspective\n",
      " gust high\n",
      " gust causing\n",
      " gurgen joe\n",
      " gupta u\n",
      " gupta thanks\n",
      " gupta thank\n",
      "\n",
      "Cluster 43:\n",
      " public servant\n",
      " career public\n",
      " foreign service\n",
      " speech gave\n",
      " want foreign\n",
      " harm come\n",
      " outstanding young\n",
      " shes absolutely\n",
      " country problem\n",
      " ha attacked\n",
      "\n",
      "Cluster 44:\n",
      " tell u\n",
      " u whats\n",
      " u youre\n",
      " doe tell\n",
      " u happened\n",
      " u going\n",
      " u jimmyjohnscom\n",
      " u want\n",
      " u think\n",
      " just tell\n",
      "\n",
      "Cluster 45:\n",
      " cnn exclusive\n",
      " exclusive interview\n",
      " vice president\n",
      " interview vice\n",
      " begin cnn\n",
      " exclusive vice\n",
      " sits cnn\n",
      " president joe\n",
      " exclusive look\n",
      " heart breaking\n",
      "\n",
      "Cluster 46:\n",
      " commerce delivery\n",
      " delivery home\n",
      " e commerce\n",
      " make e\n",
      " state postal\n",
      " service make\n",
      " postal service\n",
      " home country\n",
      " united state\n",
      " gust causing\n",
      "\n",
      "Cluster 47:\n",
      " evan thank\n",
      " right evan\n",
      " liberty biberty\n",
      " 速 vaccine\n",
      " gust high\n",
      " gust causing\n",
      " gurgen joe\n",
      " gupta u\n",
      " gupta thanks\n",
      " gupta thank\n",
      "\n",
      "Cluster 48:\n",
      " include lactic\n",
      " acid buildup\n",
      " threatening effect\n",
      " lactic acid\n",
      " buildup severe\n",
      " severe liver\n",
      " life threatening\n",
      " effect include\n",
      " liver problem\n",
      " gust causing\n",
      "\n",
      "Cluster 49:\n",
      " doctor humira\n",
      " talked doctor\n",
      " ask doctor\n",
      " say ha\n",
      " gupta professor\n",
      " gust high\n",
      " gust causing\n",
      " gurgen joe\n",
      " gupta u\n",
      " gupta thanks\n",
      "\n",
      "Cluster 50:\n",
      " feature richer\n",
      " new feature\n",
      " richer story\n",
      " strengthen bond\n",
      " dad strengthen\n",
      " bond share\n",
      " story dad\n",
      " ha new\n",
      " guy american\n",
      " gupta joining\n",
      "\n",
      "Cluster 51:\n",
      " youre saying\n",
      " like youre\n",
      " saying lessen\n",
      " saying dont\n",
      " exactly youre\n",
      " really think\n",
      " thats youre\n",
      " let youre\n",
      " think youre\n",
      " think really\n",
      "\n",
      "Cluster 52:\n",
      " untapped potential\n",
      " look room\n",
      " 速 vaccine\n",
      " gust mile\n",
      " gust high\n",
      " gust causing\n",
      " gurgen joe\n",
      " gupta u\n",
      " gupta thanks\n",
      " gupta thank\n",
      "\n",
      "Cluster 53:\n",
      " thats eatin\n",
      " eatin good\n",
      " good neighborhood\n",
      " starting thats\n",
      " burger starting\n",
      " applebees handcrafted\n",
      " handcrafted burger\n",
      " just speaker\n",
      " speaker just\n",
      " gupta thank\n",
      "\n",
      "Cluster 54:\n",
      " thats right\n",
      " reporter thats\n",
      " plan thats\n",
      " think thats\n",
      " right wolf\n",
      " right fred\n",
      " right christi\n",
      " right john\n",
      " right thing\n",
      " right poppy\n",
      "\n",
      "Cluster 55:\n",
      " white house\n",
      " house counsel\n",
      " house ha\n",
      " president trump\n",
      " house official\n",
      " house correspondent\n",
      " house meeting\n",
      " trump white\n",
      " house president\n",
      " inside white\n",
      "\n",
      "Cluster 56:\n",
      " new year\n",
      " happy new\n",
      " year eve\n",
      " year day\n",
      " early new\n",
      " year resolution\n",
      " christmas happy\n",
      " year family\n",
      " merry christmas\n",
      " year nashville\n",
      "\n",
      "Cluster 57:\n",
      " laundry sanitizer\n",
      " lysol laundry\n",
      " sanitizer kill\n",
      " kill bacteria\n",
      " kill bleach\n",
      " adding lysol\n",
      " detergent doesnt\n",
      " bacteria adding\n",
      " doesnt kill\n",
      " searching free\n",
      "\n",
      "Cluster 58:\n",
      " fight infection\n",
      " lower ability\n",
      " ability fight\n",
      " humira lower\n",
      " infection including\n",
      " including tuberculosis\n",
      " infection increase\n",
      " risk infection\n",
      " increase risk\n",
      " rinvoq lower\n",
      "\n",
      "Cluster 59:\n",
      " doctor diabetic\n",
      " diabetic retinopathy\n",
      " retinopathy vision\n",
      " vision change\n",
      " tell doctor\n",
      " tapper start\n",
      " lead jake\n",
      " jake tapper\n",
      " start right\n",
      " gupta cnn\n",
      "\n",
      "Cluster 60:\n",
      " tum tum\n",
      " tu tum\n",
      " tu tu\n",
      " tum tu\n",
      " cooling sensation\n",
      " tum new\n",
      " new tum\n",
      " bite cooling\n",
      " tum chewy\n",
      " chewy bite\n",
      "\n",
      "Cluster 61:\n",
      " patient cared\n",
      " 速 vaccine\n",
      " gupta talk\n",
      " gust hurricane\n",
      " gust high\n",
      " gust causing\n",
      " gurgen joe\n",
      " gupta u\n",
      " gupta thanks\n",
      " gupta thank\n",
      "\n",
      "Cluster 62:\n",
      " good evening\n",
      " gentleman good\n",
      " evening sir\n",
      " evening way\n",
      " evening lady\n",
      " lady gentleman\n",
      " hello good\n",
      " evening gentleman\n",
      " garlique good\n",
      " anderson good\n",
      "\n",
      "Cluster 63:\n",
      " access g\n",
      " g t\n",
      " american access\n",
      " million american\n",
      " t mobile\n",
      " 速 vaccine\n",
      " gupta professor\n",
      " gust causing\n",
      " gurgen joe\n",
      " gupta u\n",
      "\n",
      "Cluster 64:\n",
      " gig minneapolis\n",
      " gupta talk\n",
      " gust mile\n",
      " gust hurricane\n",
      " gust high\n",
      " gust causing\n",
      " gurgen joe\n",
      " gupta u\n",
      " gupta thanks\n",
      " gupta thank\n",
      "\n",
      "Cluster 65:\n",
      " pm eastern\n",
      " tonight pm\n",
      " eastern cnn\n",
      " sunday pm\n",
      " eastern time\n",
      " right cnn\n",
      " start pm\n",
      " eastern right\n",
      " tomorrow pm\n",
      " special live\n",
      "\n",
      "Cluster 66:\n",
      " symbicort mean\n",
      " day better\n",
      " mean day\n",
      " better breathing\n",
      " investigation significant\n",
      " gupta professor\n",
      " gust hurricane\n",
      " gust high\n",
      " gust causing\n",
      " gurgen joe\n",
      "\n",
      "Cluster 67:\n",
      " thank time\n",
      " kirby thank\n",
      " admiral kirby\n",
      " time explaining\n",
      " time morning\n",
      " explaining u\n",
      " pastor michael\n",
      " governor hutchinson\n",
      " congresswoman thank\n",
      " doctor thank\n",
      "\n",
      "Cluster 68:\n",
      " mother began\n",
      " forgetting thing\n",
      " began forgetting\n",
      " turn information\n",
      " know turn\n",
      " thing didnt\n",
      " didnt know\n",
      " 速 vaccine\n",
      " gust high\n",
      " gust causing\n",
      "\n",
      "Cluster 69:\n",
      " trust em\n",
      " proud aag\n",
      " aag trust\n",
      " em think\n",
      " im proud\n",
      " gupta thank\n",
      " gust mile\n",
      " gust hurricane\n",
      " gust high\n",
      " gust causing\n",
      "\n",
      "Cluster 70:\n",
      " good morning\n",
      " reporter good\n",
      " morning john\n",
      " morning christine\n",
      " morning guy\n",
      " morning christi\n",
      " morning erica\n",
      " morning mr\n",
      " morning alisyn\n",
      " yeah good\n",
      "\n",
      "Cluster 71:\n",
      " aide come\n",
      " like ask\n",
      " military aide\n",
      " come forward\n",
      " gupta professor\n",
      " gust hurricane\n",
      " gust high\n",
      " gust causing\n",
      " gurgen joe\n",
      " gupta u\n",
      "\n",
      "Cluster 72:\n",
      " expected dock\n",
      " ship expected\n",
      " princess cruise\n",
      " grand princess\n",
      " cruise ship\n",
      " dock oakland\n",
      " dock today\n",
      " gupta dr\n",
      " gupta cnn\n",
      " gust high\n",
      "\n",
      "Cluster 73:\n",
      " paying arm\n",
      " leg postage\n",
      " arm leg\n",
      " business paying\n",
      " started business\n",
      " visit lifelockcomtv\n",
      " jet moneyback\n",
      " moneyback guarantee\n",
      " try wet\n",
      " wet jet\n",
      "\n",
      "Cluster 74:\n",
      " astrazeneca able\n",
      " able help\n",
      " medication astrazeneca\n",
      " afford medication\n",
      " ha pretty\n",
      " president ha\n",
      " gupta dr\n",
      " gupta ha\n",
      " gust causing\n",
      " gurgen joe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print out most indicative words\n",
    "terms = vect.get_feature_names()\n",
    "order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "for i in range(75):\n",
    "    print (\"Cluster %d:\" % i)\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print (' %s' % terms[ind])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_df['cluster'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view sentences for each cluster\n",
    "file_contents = ''\n",
    "for i in range(75):\n",
    "    file_contents += 'Cluster {}\\n'.format(i)\n",
    "    counter = 0\n",
    "    for index, row in cnn_df[cnn_df.cluster == i].iterrows():\n",
    "        file_contents += row['sentence'] + '\\n'\n",
    "        counter += 1\n",
    "        if counter > 20:\n",
    "            break\n",
    "    file_contents += '\\n'\n",
    "with open('../data/interim/cnn-sentence-check-2.txt', 'w') as f:\n",
    "    f.write(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>325472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>3195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentence\n",
       "cluster          \n",
       "1          325472\n",
       "55           3195\n",
       "41            905\n",
       "4             560\n",
       "30            527\n",
       "...           ...\n",
       "32              4\n",
       "52              3\n",
       "9               2\n",
       "71              2\n",
       "0               1\n",
       "\n",
       "[75 rows x 1 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of sentences in each cluster\n",
    "cnn_df[['cluster', 'sentence']].groupby('cluster').count().sort_values(by='sentence', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news_cluster</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>327394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sentence\n",
       "news_cluster          \n",
       "0               327394\n",
       "1                 7598"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_clusters=[2, 5, 7, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 31, 33, 36,\n",
    "             37, 38, 39, 42, 48, 49, 50, 53, 57, 58, 59, 60, 61, 63, 64, 66, 68, 69, 73, 74]\n",
    "news_clusters=[0, 3, 6, 9, 10, 12, 16, 25, 26, 30, 32, 34, 35, 40, 41, 43, 44, 45, 46,\n",
    "              47, 51, 54, 55, 56, 62, 65, 67, 70, 71, 72]\n",
    "mixed=[1, 4, 8, 11, 14]\n",
    "cnn_df['ad_cluster'] = 0\n",
    "cnn_df['news_cluster'] = 0\n",
    "cnn_df['ad_cluster'] = cnn_df['cluster'].isin(ad_clusters)\n",
    "cnn_df['news_cluster'] = cnn_df['cluster'].isin(news_clusters)\n",
    "cnn_df = cnn_df.mask(cnn_df == True, 1)\n",
    "cnn_df = cnn_df.mask(cnn_df == False, 0)\n",
    "cnn_df[['news_cluster', 'sentence']].groupby('news_cluster').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create First-Pass Model\n",
    "\n",
    "Using the clustering, I now create a LogisticRegression model as a first pass model, to help create more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8903"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dataframe of only the sentences that are definitively ads or news\n",
    "coded_df = cnn_df[(cnn_df.ad_cluster == 1) | (cnn_df.news_cluster == 1)]\n",
    "len(coded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8903 entries, 27 to 334982\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   identifier    8903 non-null   object\n",
      " 1   sentence      8903 non-null   object\n",
      " 2   start_snip    8903 non-null   int64 \n",
      " 3   end_snip      8903 non-null   int64 \n",
      " 4   contributor   8903 non-null   object\n",
      " 5   runtime       8903 non-null   object\n",
      " 6   start_time    8903 non-null   object\n",
      " 7   stop_time     8903 non-null   object\n",
      " 8   subjects      8903 non-null   object\n",
      " 9   cluster       8903 non-null   int32 \n",
      " 10  ad_cluster    8903 non-null   int32 \n",
      " 11  news_cluster  8903 non-null   int32 \n",
      "dtypes: int32(3), int64(2), object(7)\n",
      "memory usage: 799.9+ KB\n"
     ]
    }
   ],
   "source": [
    "coded_df = coded_df.astype({'ad_cluster': 'int32', 'news_cluster': 'int32'})\n",
    "coded_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new vectorizer with 1 and 2-gramms\n",
    "vect_2 = TfidfVectorizer(tokenizer=LemmaTokenizer(), strip_accents='unicode', stop_words='english', \n",
    "                       min_df=2, max_df=0.3, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\envs\\ad-finder-cc\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score: 0.9981280419318608\n"
     ]
    }
   ],
   "source": [
    "y = np.array(coded_df.ad_cluster)\n",
    "X_corpus = np.array(coded_df['sentence'])\n",
    "X_corpus_train, X_corpus_test, y_train, y_test = train_test_split(X_corpus, y, test_size=0.3, random_state=18)\n",
    "\n",
    "X_train = vect_2.fit_transform(X_corpus_train)\n",
    "\n",
    "X_test = vect_2.transform(X_corpus_test)\n",
    "\n",
    "log = LogisticRegression()\n",
    "log.fit(X_train, y_train)\n",
    "log_score = log.score(X_test, y_test)\n",
    "print('Logistic Regression Score: {}'.format(log_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2297    0]\n",
      " [   5  369]]\n"
     ]
    }
   ],
   "source": [
    "pred = log.predict(X_test)\n",
    "c=confusion_matrix(y_test, pred)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_df.to_csv('../data/interim/cnn-sentences-clustered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(log, open('../models/cnn_1st_pass_logit.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Apply Logit Model to Snippets\n",
    "\n",
    "Applying the Logit model to snippets and then breaking the snippets into sentences helps identify snippets with ads in them, and since ads are likely to be next to each other, the output of this model is a useful feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340147"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_snips = pd.read_csv('../data/interim/cnn-last-year-parsed.csv')\n",
    "len(cnn_snips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33299"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get only cnn shows from show-based train_test_split\n",
    "cnn_snips = cnn_snips.set_index('identifier').join(cnn_shows.set_index('identifier'), on='identifier', how='inner').reset_index().copy()\n",
    "len(cnn_snips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>start_snip</th>\n",
       "      <th>end_snip</th>\n",
       "      <th>snippet</th>\n",
       "      <th>contributor</th>\n",
       "      <th>runtime</th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>subjects</th>\n",
       "      <th>show_name</th>\n",
       "      <th>snip_ad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>305</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>now the fastest, most reliable internet can he...</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>306</td>\n",
       "      <td>60</td>\n",
       "      <td>120</td>\n",
       "      <td>states and of course all around the world. i'm...</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>307</td>\n",
       "      <td>120</td>\n",
       "      <td>180</td>\n",
       "      <td>prayer. citizens all across the country came t...</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>308</td>\n",
       "      <td>180</td>\n",
       "      <td>240</td>\n",
       "      <td>symbolism and on ceremony. but somewhat short ...</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>309</td>\n",
       "      <td>240</td>\n",
       "      <td>300</td>\n",
       "      <td>been violated by north korea's may 9th firing ...</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               identifier  Unnamed: 0  start_snip  end_snip  \\\n",
       "0  CNNW_20190528_060000_CNN_Newsroom_Live         305           0        60   \n",
       "1  CNNW_20190528_060000_CNN_Newsroom_Live         306          60       120   \n",
       "2  CNNW_20190528_060000_CNN_Newsroom_Live         307         120       180   \n",
       "3  CNNW_20190528_060000_CNN_Newsroom_Live         308         180       240   \n",
       "4  CNNW_20190528_060000_CNN_Newsroom_Live         309         240       300   \n",
       "\n",
       "                                             snippet contributor   runtime  \\\n",
       "0  now the fastest, most reliable internet can he...        CNNW  01:00:58   \n",
       "1  states and of course all around the world. i'm...        CNNW  01:00:58   \n",
       "2  prayer. citizens all across the country came t...        CNNW  01:00:58   \n",
       "3  symbolism and on ceremony. but somewhat short ...        CNNW  01:00:58   \n",
       "4  been violated by north korea's may 9th firing ...        CNNW  01:00:58   \n",
       "\n",
       "            start_time            stop_time  \\\n",
       "0  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "1  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "2  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "3  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "4  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "\n",
       "                                            subjects          show_name  \\\n",
       "0  ['trump', 'north korea', 'japan', 'rosemary', ...  CNN_Newsroom_Live   \n",
       "1  ['trump', 'north korea', 'japan', 'rosemary', ...  CNN_Newsroom_Live   \n",
       "2  ['trump', 'north korea', 'japan', 'rosemary', ...  CNN_Newsroom_Live   \n",
       "3  ['trump', 'north korea', 'japan', 'rosemary', ...  CNN_Newsroom_Live   \n",
       "4  ['trump', 'north korea', 'japan', 'rosemary', ...  CNN_Newsroom_Live   \n",
       "\n",
       "   snip_ad  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_snips = cnn_snips.dropna()\n",
    "X_snips = np.array(cnn_snips['snippet'])\n",
    "X_snips_bow = vect_2.transform(X_snips)\n",
    "pred = log.predict(X_snips_bow)\n",
    "cnn_snips['snip_ad'] = pred\n",
    "cnn_snips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>contributor</th>\n",
       "      <th>runtime</th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>subjects</th>\n",
       "      <th>cluster</th>\n",
       "      <th>ad_cluster</th>\n",
       "      <th>news_cluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identifier</th>\n",
       "      <th>start_snip</th>\n",
       "      <th>end_snip</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">CNNW_20190528_060000_CNN_Newsroom_Live</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>60</th>\n",
       "      <td>now the fastest, most reliable internet can he...</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>that's simple, easy, awesome.</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>taxi!</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>should i have stopped her?</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>save hundreds of dollars a year when you get i...</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                     sentence  \\\n",
       "identifier                             start_snip end_snip                                                      \n",
       "CNNW_20190528_060000_CNN_Newsroom_Live 0          60        now the fastest, most reliable internet can he...   \n",
       "                                                  60                            that's simple, easy, awesome.   \n",
       "                                                  60                                                    taxi!   \n",
       "                                                  60                               should i have stopped her?   \n",
       "                                                  60        save hundreds of dollars a year when you get i...   \n",
       "\n",
       "                                                           contributor  \\\n",
       "identifier                             start_snip end_snip               \n",
       "CNNW_20190528_060000_CNN_Newsroom_Live 0          60              CNNW   \n",
       "                                                  60              CNNW   \n",
       "                                                  60              CNNW   \n",
       "                                                  60              CNNW   \n",
       "                                                  60              CNNW   \n",
       "\n",
       "                                                             runtime  \\\n",
       "identifier                             start_snip end_snip             \n",
       "CNNW_20190528_060000_CNN_Newsroom_Live 0          60        01:00:58   \n",
       "                                                  60        01:00:58   \n",
       "                                                  60        01:00:58   \n",
       "                                                  60        01:00:58   \n",
       "                                                  60        01:00:58   \n",
       "\n",
       "                                                                     start_time  \\\n",
       "identifier                             start_snip end_snip                        \n",
       "CNNW_20190528_060000_CNN_Newsroom_Live 0          60        2019-05-28 06:00:00   \n",
       "                                                  60        2019-05-28 06:00:00   \n",
       "                                                  60        2019-05-28 06:00:00   \n",
       "                                                  60        2019-05-28 06:00:00   \n",
       "                                                  60        2019-05-28 06:00:00   \n",
       "\n",
       "                                                                      stop_time  \\\n",
       "identifier                             start_snip end_snip                        \n",
       "CNNW_20190528_060000_CNN_Newsroom_Live 0          60        2019-05-28 07:00:59   \n",
       "                                                  60        2019-05-28 07:00:59   \n",
       "                                                  60        2019-05-28 07:00:59   \n",
       "                                                  60        2019-05-28 07:00:59   \n",
       "                                                  60        2019-05-28 07:00:59   \n",
       "\n",
       "                                                                                                     subjects  \\\n",
       "identifier                             start_snip end_snip                                                      \n",
       "CNNW_20190528_060000_CNN_Newsroom_Live 0          60        ['trump', 'north korea', 'japan', 'rosemary', ...   \n",
       "                                                  60        ['trump', 'north korea', 'japan', 'rosemary', ...   \n",
       "                                                  60        ['trump', 'north korea', 'japan', 'rosemary', ...   \n",
       "                                                  60        ['trump', 'north korea', 'japan', 'rosemary', ...   \n",
       "                                                  60        ['trump', 'north korea', 'japan', 'rosemary', ...   \n",
       "\n",
       "                                                            cluster  \\\n",
       "identifier                             start_snip end_snip            \n",
       "CNNW_20190528_060000_CNN_Newsroom_Live 0          60              1   \n",
       "                                                  60              1   \n",
       "                                                  60              1   \n",
       "                                                  60              1   \n",
       "                                                  60              1   \n",
       "\n",
       "                                                           ad_cluster  \\\n",
       "identifier                             start_snip end_snip              \n",
       "CNNW_20190528_060000_CNN_Newsroom_Live 0          60                0   \n",
       "                                                  60                0   \n",
       "                                                  60                0   \n",
       "                                                  60                0   \n",
       "                                                  60                0   \n",
       "\n",
       "                                                           news_cluster  \n",
       "identifier                             start_snip end_snip               \n",
       "CNNW_20190528_060000_CNN_Newsroom_Live 0          60                  0  \n",
       "                                                  60                  0  \n",
       "                                                  60                  0  \n",
       "                                                  60                  0  \n",
       "                                                  60                  0  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_df = cnn_df.set_index(['identifier', 'start_snip', 'end_snip'])\n",
    "cnn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_snips = cnn_snips[['identifier', 'start_snip', 'end_snip', 'snip_ad']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_snips = cnn_snips.set_index(['identifier', 'start_snip', 'end_snip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_df = cnn_df.join(cnn_snips, on=['identifier', 'start_snip', 'end_snip'], how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Apply LDA\n",
    "\n",
    "Perhaps LDA percentages will be a feature than can predict ads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['now the fastest most reliable internet can help you save on your wireless bill',\n",
       " 'thats simple easy awesome',\n",
       " 'taxi',\n",
       " 'should i have stopped her',\n",
       " 'save hundreds of dollars a year when you get internet and mobile together']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_corpus = list(clean_sent(cnn_df['sentence']))\n",
    "X_corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vect.fit_transform(X_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweak the two parameters below\n",
    "number_topics = 75\n",
    "number_words = 10\n",
    "\n",
    "# Create and fit the LDA model\n",
    "lda = LDA(n_components=number_topics, n_jobs=-1)\n",
    "lda_results = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def print_topics(model, count_vectorizer, n_top_words):\n",
    "    words = count_vectorizer.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\" \".join([words[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics found via LDA:\n",
      "\n",
      "Topic #0:\n",
      "im sorry cancer treatment treatment center center america good luck promise prove movement automatically automatically adjusts pain happens sens movement\n",
      "\n",
      "Topic #1:\n",
      "white house president trump did say glad help appointment available tested positive thats president just month positive coronavirus come man\n",
      "\n",
      "Topic #2:\n",
      "make sense hillary clinton good night christine roman make difference wa clear think right signal reach reach farther thats correct\n",
      "\n",
      "Topic #3:\n",
      "barack obama robert mueller youre looking really interesting irobot roombaTM middle class told u people achieved skin month achieved clearer\n",
      "\n",
      "Topic #4:\n",
      "joe biden wa wrong social medium going come did make bayer science surprisingly painless let say really need thats coming\n",
      "\n",
      "Topic #5:\n",
      "dont understand people say thats big say dont chief justice think democrat mar lago homeland security abnormal bleeding foreign leader\n",
      "\n",
      "Topic #6:\n",
      "make life life simple xfinity make poppy harlow thats need im poppy jerry nadler future generation totally blind going ask\n",
      "\n",
      "Topic #7:\n",
      "good evening african american unlimited data people died andrew yang im happy theyre looking otezla clearer clearer skin skin achievable\n",
      "\n",
      "Topic #8:\n",
      "doesnt want oh yeah people coming short break july th body compass short term death penalty trip need need love\n",
      "\n",
      "Topic #9:\n",
      "severe diarrhea cause severe like symptom nausea vomiting diarrhea nausea just right flu like symptom sore tell doctor just imagine\n",
      "\n",
      "Topic #10:\n",
      "dont want people want thats otezla let look let just director national just say national intelligence unlike parent senate trial\n",
      "\n",
      "Topic #11:\n",
      "whats going thank watching e mail stevens phone vo national pretty good ha right confirmed case think im doe make\n",
      "\n",
      "Topic #12:\n",
      "breathe easy long way police say im worried want listen wa running therabreath walmart say im mile card mayor pete\n",
      "\n",
      "Topic #13:\n",
      "good news reaction occur allergic reaction yes gently warming foot gently warming doe president best friend european union want come\n",
      "\n",
      "Topic #14:\n",
      "cy pelosi dont use article impeachment use youre youre allergic think important member congress speaker pelosi house speaker speaker cy\n",
      "\n",
      "Topic #15:\n",
      "national security think know let play theyve got people hearing visit sprintrelaycom loss visit hearing loss thank god dont just\n",
      "\n",
      "Topic #16:\n",
      "dont like thanks having sit baa think think make feel anti semitic ah relax poll number thats said wa going\n",
      "\n",
      "Topic #17:\n",
      "thats great intelligence committee mike bloomberg know thing answer question vice pres great paint kind thing thats kind house intelligence\n",
      "\n",
      "Topic #18:\n",
      "thats important increased risk car insurance minute save otezla associated risk depression associated increased ha taken need help look forward\n",
      "\n",
      "Topic #19:\n",
      "know wa know theyre common effect michael bloomberg did know win win effect nausea situation room theyre going supreme court\n",
      "\n",
      "Topic #20:\n",
      "bernie sander elizabeth warren day day yes sir brooke baldwin doe tell senator bernie im brooke wa way want president\n",
      "\n",
      "Topic #21:\n",
      "thank u president biden different way vice president intelligence community risk infection taking care stay tuned infection lower increase risk\n",
      "\n",
      "Topic #22:\n",
      "really appreciate inspire hope lower ac know know thing going big difference early start little thing thing big welcome early\n",
      "\n",
      "Topic #23:\n",
      "let bring thats really really important coverage continues impeachment process doe say period time wa real press conference political analyst\n",
      "\n",
      "Topic #24:\n",
      "thats right want say rudy giuliani wear mask doesnt know phone number reporter thats know phone u know free information\n",
      "\n",
      "Topic #25:\n",
      "think going just dont prime minister boris johnson whistle blower doing thing let know think good blower complaint havent heard\n",
      "\n",
      "Topic #26:\n",
      "mitch mcconnell want know climate change knew wa dont care majority leader adam schiff tell cnn wa interesting senate majority\n",
      "\n",
      "Topic #27:\n",
      "joining u thank joining little bit t mobile tom steyer just beginning lot thing reason join wa able john mccain\n",
      "\n",
      "Topic #28:\n",
      "sleep number havent seen watching cnn youre watching cheer applause good job federal government ha gone im wondering trying figure\n",
      "\n",
      "Topic #29:\n",
      "long time thats just visit store click visit store today just day time ago reporter yeah ill tell member life\n",
      "\n",
      "Topic #30:\n",
      "ill pas tax fee fee included obstruction justice want ask gram sugar wa important protein gram dont really gram protein\n",
      "\n",
      "Topic #31:\n",
      "xfinitycommoving started big deal lot money obstruction congress make deal president say got lot thats theyre hot spot rule law\n",
      "\n",
      "Topic #32:\n",
      "north korea know youre kim jong make decision mobile match ive got foreign policy weve heard just ahead match discount\n",
      "\n",
      "Topic #33:\n",
      "good morning healthier brain think theyre ask question going vote reporter good moderate severe approval rating severe plaque good reason\n",
      "\n",
      "Topic #34:\n",
      "donald trump better life new day republican party witch hunt let clear iowa caucus tested tb treatment tested think thing\n",
      "\n",
      "Topic #35:\n",
      "cnn newsroom live cnn thank sir town hall plus month camera clicking youre live new hampshire said yes home depot\n",
      "\n",
      "Topic #36:\n",
      "going happen ive seen exactly right thats exactly otezla cream really good just got upper respiratory headache occur respiratory tract\n",
      "\n",
      "Topic #37:\n",
      "want talk kamala harris wa great just want cory booker weve seen think really oral b thats case good question\n",
      "\n",
      "Topic #38:\n",
      "breaking news week ago abuse power want hear right thing think youre don lemon tasting ensure theyre getting great tasting\n",
      "\n",
      "Topic #39:\n",
      "thanks joining new york joining u talk doctor know going ha changed going right support brand memory support end year\n",
      "\n",
      "Topic #40:\n",
      "vice president el paso president joe new year joe biden police officer mike penny month ago world war ambassador taylor\n",
      "\n",
      "Topic #41:\n",
      "dont start fight infection humira infection start humira lower ability ability fight humira lower thats u quick break coffee delicious\n",
      "\n",
      "Topic #42:\n",
      "wearing mask debate stage tell story new information wa lot american people state union god bless thats lot just look\n",
      "\n",
      "Topic #43:\n",
      "john bolton jim sciutto wa time im jim took place vice president national security say yes party line president trump\n",
      "\n",
      "Topic #44:\n",
      "mike pompeo secretary state know exactly theyre saying said im la vega state mike try listerine速 beat donald thing say\n",
      "\n",
      "Topic #45:\n",
      "thanks u youre saying lot people stop treatment monitor weight doctor monitor weight stop attorney general just minute meet sergio\n",
      "\n",
      "Topic #46:\n",
      "dont know thank having hong kong cnn breaking breaking news know whats like wa high crime lot time looked like\n",
      "\n",
      "Topic #47:\n",
      "united state president united im talking help asleep know think ensure max max protein going start know mean pay attention\n",
      "\n",
      "Topic #48:\n",
      "im going want want use want born ride ride progressive house counsel public opinion memorial day cnn ha white house\n",
      "\n",
      "Topic #49:\n",
      "weve got look like im just id like yes yes said going ask doctor stock market thats problem just saying\n",
      "\n",
      "Topic #50:\n",
      "join u law enforcement youve seen aleve pm democrat republican wa pretty thats eatin eatin good good neighborhood going lot\n",
      "\n",
      "Topic #51:\n",
      "doe mean limited time data plan samsung galaxy alcohol use want read decrease alcohol want thank didnt like galaxy note\n",
      "\n",
      "Topic #52:\n",
      "president did did wrong just going thats easy executive privilege thing want coming day make mistake trump administration dont mad\n",
      "\n",
      "Topic #53:\n",
      "social distancing people know president want going work xfinity store thank reporting running president trying make working hard store today\n",
      "\n",
      "Topic #54:\n",
      "let listen let send gon na really want lot question know right day week know really york city new york\n",
      "\n",
      "Topic #55:\n",
      "mental health thats way aisle store vitamin aisle shape future thats interesting thousand people news continues health problem mr tapper\n",
      "\n",
      "Topic #56:\n",
      "stay home im glad senator sander billion problem home order thing happen ha excellent amy klobuchar say oh life t\n",
      "\n",
      "Topic #57:\n",
      "let talk dont believe people taking weight loss good hand taking otezla reported weight otezla reported doing right vitamin mineral\n",
      "\n",
      "Topic #58:\n",
      "big question talking point youve got super soft bum bum retire better im real answered question june th moving internet\n",
      "\n",
      "Topic #59:\n",
      "didnt know let start south carolina past hour wa little book hiltoncom cascade platinum match guarantee price match thats ficial\n",
      "\n",
      "Topic #60:\n",
      "whats happening united state state world chief staff welcome viewer viewer united mick mulvaney just said just like thats whats\n",
      "\n",
      "Topic #61:\n",
      "tell u pay need let discus better sleep promise better really promise liberty mutual insurance pay brand new know did\n",
      "\n",
      "Topic #62:\n",
      "dont think year old thats true wa like wa good wa year mile hour theyre doing know say year row\n",
      "\n",
      "Topic #63:\n",
      "pro quo quid pro didnt want just moment think need know dont volvo xc wa quid youre pregt talk advisor\n",
      "\n",
      "Topic #64:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let ask camera figure wall street saved life im tryin know people want play et cetera looking forward pd l\n",
      "\n",
      "Topic #65:\n",
      "health care help u care worker tax return dont wait going try president impeached said want john berman u asleep\n",
      "\n",
      "Topic #66:\n",
      "mitt romney capital group going talk know thats better choice wa talking bad thing jim acosta saving service people color\n",
      "\n",
      "Topic #67:\n",
      "wa easy youre right im saying award winning ha happened really hard mno kiddingrd daughter maria different thing red flag\n",
      "\n",
      "Topic #68:\n",
      "im sure dont worry doesnt mean want bring wa perfect need know kaitlan collins coronavirus case personal attorney going continue\n",
      "\n",
      "Topic #69:\n",
      "wa really super tuesday ha come whoo hoo hurricane dorian hals heart did come general election wash hand time u\n",
      "\n",
      "Topic #70:\n",
      "thats good chris cuomo thank coming good point didnt say great job talk u think real want start think did\n",
      "\n",
      "Topic #71:\n",
      "stay u oh god thats thing im doing thats im doesnt matter lindsey graham wa big puerto rico inside politics\n",
      "\n",
      "Topic #72:\n",
      "appreciate time going say youre welcome say thing like pro like netflix whoa hoa hoa hoa dont need jared kushner\n",
      "\n",
      "Topic #73:\n",
      "bend waist cnn tonight doctor check doctor history history depression thought feeling feeling develop suicidal thought treatment doctor read mind\n",
      "\n",
      "Topic #74:\n",
      "mr president saudi arabia thats simple simple easy easy awesome state america thank mr new york united state just way\n"
     ]
    }
   ],
   "source": [
    "# Print the topics found by the LDA model\n",
    "print(\"Topics found via LDA:\")\n",
    "print_topics(lda, vect, number_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>start_snip</th>\n",
       "      <th>end_snip</th>\n",
       "      <th>sentence</th>\n",
       "      <th>contributor</th>\n",
       "      <th>runtime</th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>subjects</th>\n",
       "      <th>cluster</th>\n",
       "      <th>ad_cluster</th>\n",
       "      <th>news_cluster</th>\n",
       "      <th>snip_ad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>now the fastest, most reliable internet can he...</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>that's simple, easy, awesome.</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>taxi!</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>should i have stopped her?</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>save hundreds of dollars a year when you get i...</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               identifier  start_snip  end_snip  \\\n",
       "0  CNNW_20190528_060000_CNN_Newsroom_Live           0        60   \n",
       "1  CNNW_20190528_060000_CNN_Newsroom_Live           0        60   \n",
       "2  CNNW_20190528_060000_CNN_Newsroom_Live           0        60   \n",
       "3  CNNW_20190528_060000_CNN_Newsroom_Live           0        60   \n",
       "4  CNNW_20190528_060000_CNN_Newsroom_Live           0        60   \n",
       "\n",
       "                                            sentence contributor   runtime  \\\n",
       "0  now the fastest, most reliable internet can he...        CNNW  01:00:58   \n",
       "1                      that's simple, easy, awesome.        CNNW  01:00:58   \n",
       "2                                              taxi!        CNNW  01:00:58   \n",
       "3                         should i have stopped her?        CNNW  01:00:58   \n",
       "4  save hundreds of dollars a year when you get i...        CNNW  01:00:58   \n",
       "\n",
       "            start_time            stop_time  \\\n",
       "0  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "1  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "2  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "3  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "4  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "\n",
       "                                            subjects  cluster ad_cluster  \\\n",
       "0  ['trump', 'north korea', 'japan', 'rosemary', ...        1          0   \n",
       "1  ['trump', 'north korea', 'japan', 'rosemary', ...        1          0   \n",
       "2  ['trump', 'north korea', 'japan', 'rosemary', ...        1          0   \n",
       "3  ['trump', 'north korea', 'japan', 'rosemary', ...        1          0   \n",
       "4  ['trump', 'north korea', 'japan', 'rosemary', ...        1          0   \n",
       "\n",
       "  news_cluster  snip_ad  \n",
       "0            0        0  \n",
       "1            0        0  \n",
       "2            0        0  \n",
       "3            0        0  \n",
       "4            0        0  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>start_snip</th>\n",
       "      <th>end_snip</th>\n",
       "      <th>sentence</th>\n",
       "      <th>contributor</th>\n",
       "      <th>runtime</th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>subjects</th>\n",
       "      <th>cluster</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_65</th>\n",
       "      <th>topic_66</th>\n",
       "      <th>topic_67</th>\n",
       "      <th>topic_68</th>\n",
       "      <th>topic_69</th>\n",
       "      <th>topic_70</th>\n",
       "      <th>topic_71</th>\n",
       "      <th>topic_72</th>\n",
       "      <th>topic_73</th>\n",
       "      <th>topic_74</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>now the fastest, most reliable internet can he...</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>that's simple, easy, awesome.</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.638587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>taxi!</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>should i have stopped her?</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>save hundreds of dollars a year when you get i...</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.005531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               identifier  start_snip  end_snip  \\\n",
       "0  CNNW_20190528_060000_CNN_Newsroom_Live           0        60   \n",
       "1  CNNW_20190528_060000_CNN_Newsroom_Live           0        60   \n",
       "2  CNNW_20190528_060000_CNN_Newsroom_Live           0        60   \n",
       "3  CNNW_20190528_060000_CNN_Newsroom_Live           0        60   \n",
       "4  CNNW_20190528_060000_CNN_Newsroom_Live           0        60   \n",
       "\n",
       "                                            sentence contributor   runtime  \\\n",
       "0  now the fastest, most reliable internet can he...        CNNW  01:00:58   \n",
       "1                      that's simple, easy, awesome.        CNNW  01:00:58   \n",
       "2                                              taxi!        CNNW  01:00:58   \n",
       "3                         should i have stopped her?        CNNW  01:00:58   \n",
       "4  save hundreds of dollars a year when you get i...        CNNW  01:00:58   \n",
       "\n",
       "            start_time            stop_time  \\\n",
       "0  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "1  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "2  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "3  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "4  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "\n",
       "                                            subjects  cluster  ...  topic_65  \\\n",
       "0  ['trump', 'north korea', 'japan', 'rosemary', ...        1  ...  0.006667   \n",
       "1  ['trump', 'north korea', 'japan', 'rosemary', ...        1  ...  0.004884   \n",
       "2  ['trump', 'north korea', 'japan', 'rosemary', ...        1  ...  0.013333   \n",
       "3  ['trump', 'north korea', 'japan', 'rosemary', ...        1  ...  0.013333   \n",
       "4  ['trump', 'north korea', 'japan', 'rosemary', ...        1  ...  0.005531   \n",
       "\n",
       "   topic_66  topic_67  topic_68  topic_69  topic_70  topic_71  topic_72  \\\n",
       "0  0.006667  0.006667  0.006667  0.006667  0.006667  0.006667  0.006667   \n",
       "1  0.004884  0.004884  0.004884  0.004884  0.004884  0.004884  0.004884   \n",
       "2  0.013333  0.013333  0.013333  0.013333  0.013333  0.013333  0.013333   \n",
       "3  0.013333  0.013333  0.013333  0.013333  0.013333  0.013333  0.013333   \n",
       "4  0.005531  0.005531  0.005531  0.005531  0.005531  0.005531  0.005531   \n",
       "\n",
       "   topic_73  topic_74  \n",
       "0  0.006667  0.006667  \n",
       "1  0.004884  0.638587  \n",
       "2  0.013333  0.013333  \n",
       "3  0.013333  0.013333  \n",
       "4  0.005531  0.005531  \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_df = pd.DataFrame(lda_results)\n",
    "lda_df.columns = ['topic_' + str(i) for i in range(75)]\n",
    "cnn_df = cnn_df.join(lda_df, how='inner')\n",
    "cnn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_df.to_csv('../data/interim/cnn-sentences-clustered-topics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Add Features #\n",
    "\n",
    "Now I will add calculated features to the dataframe to help diagnose blocks of ads, or words that may prefigure ads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>identifier</th>\n",
       "      <th>start_snip</th>\n",
       "      <th>end_snip</th>\n",
       "      <th>sentence</th>\n",
       "      <th>contributor</th>\n",
       "      <th>runtime</th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>subjects</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_65</th>\n",
       "      <th>topic_66</th>\n",
       "      <th>topic_67</th>\n",
       "      <th>topic_68</th>\n",
       "      <th>topic_69</th>\n",
       "      <th>topic_70</th>\n",
       "      <th>topic_71</th>\n",
       "      <th>topic_72</th>\n",
       "      <th>topic_73</th>\n",
       "      <th>topic_74</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>now the fastest, most reliable internet can he...</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>that's simple, easy, awesome.</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.638587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>taxi!</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>should i have stopped her?</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>save hundreds of dollars a year when you get i...</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.005531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                              identifier  start_snip  end_snip  \\\n",
       "0           0  CNNW_20190528_060000_CNN_Newsroom_Live           0        60   \n",
       "1           1  CNNW_20190528_060000_CNN_Newsroom_Live           0        60   \n",
       "2           2  CNNW_20190528_060000_CNN_Newsroom_Live           0        60   \n",
       "3           3  CNNW_20190528_060000_CNN_Newsroom_Live           0        60   \n",
       "4           4  CNNW_20190528_060000_CNN_Newsroom_Live           0        60   \n",
       "\n",
       "                                            sentence contributor   runtime  \\\n",
       "0  now the fastest, most reliable internet can he...        CNNW  01:00:58   \n",
       "1                      that's simple, easy, awesome.        CNNW  01:00:58   \n",
       "2                                              taxi!        CNNW  01:00:58   \n",
       "3                         should i have stopped her?        CNNW  01:00:58   \n",
       "4  save hundreds of dollars a year when you get i...        CNNW  01:00:58   \n",
       "\n",
       "            start_time            stop_time  \\\n",
       "0  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "1  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "2  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "3  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "4  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "\n",
       "                                            subjects  ...  topic_65  topic_66  \\\n",
       "0  ['trump', 'north korea', 'japan', 'rosemary', ...  ...  0.006667  0.006667   \n",
       "1  ['trump', 'north korea', 'japan', 'rosemary', ...  ...  0.004884  0.004884   \n",
       "2  ['trump', 'north korea', 'japan', 'rosemary', ...  ...  0.013333  0.013333   \n",
       "3  ['trump', 'north korea', 'japan', 'rosemary', ...  ...  0.013333  0.013333   \n",
       "4  ['trump', 'north korea', 'japan', 'rosemary', ...  ...  0.005531  0.005531   \n",
       "\n",
       "   topic_67  topic_68  topic_69  topic_70  topic_71  topic_72  topic_73  \\\n",
       "0  0.006667  0.006667  0.006667  0.006667  0.006667  0.006667  0.006667   \n",
       "1  0.004884  0.004884  0.004884  0.004884  0.004884  0.004884  0.004884   \n",
       "2  0.013333  0.013333  0.013333  0.013333  0.013333  0.013333  0.013333   \n",
       "3  0.013333  0.013333  0.013333  0.013333  0.013333  0.013333  0.013333   \n",
       "4  0.005531  0.005531  0.005531  0.005531  0.005531  0.005531  0.005531   \n",
       "\n",
       "   topic_74  \n",
       "0  0.006667  \n",
       "1  0.638587  \n",
       "2  0.013333  \n",
       "3  0.013333  \n",
       "4  0.005531  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_df = pd.read_csv('../data/interim/cnn-sentences-clustered-topics.csv')\n",
    "len_df = len(cnn_df)\n",
    "\n",
    "ad_next_words = ['back', 'return', 'ahead', 'go away', 'next', 'miss', 'after this', 'tuned', 'applause', 'appreciate']\n",
    "ad_prev_words = ['back', 'welcome', 'talk', 'applause', 'good evening', 'good morning', 'appreciate']\n",
    "\n",
    "cnn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in cnn_df.iterrows():\n",
    "    sentence = row['sentence']\n",
    "    if (i < len_df - 1):\n",
    "        for word in ad_next_words:\n",
    "            if (word in sentence):\n",
    "                cnn_df.loc[i + 1,'has_prev_' + word] = 1\n",
    "                if (i + 2) < len_df:\n",
    "                    cnn_df.loc[i + 2,'has_prev_' + word] = 1\n",
    "                if (i + 3) < len_df:\n",
    "                    cnn_df.loc[i + 2,'has_prev_' + word] = 1\n",
    "    if (i > 0):\n",
    "        for word in ad_prev_words:\n",
    "            if (word in sentence):\n",
    "                cnn_df.loc[i - 1, 'has_next_' + word] = 1\n",
    "                if (i - 2) > 0:\n",
    "                    cnn_df.loc[i - 2, 'has_next_' + word] = 1\n",
    "                if (i - 3) > 0:\n",
    "                    cnn_df.loc[i - 3, 'has_next_' + word] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>identifier</th>\n",
       "      <th>start_snip</th>\n",
       "      <th>end_snip</th>\n",
       "      <th>sentence</th>\n",
       "      <th>contributor</th>\n",
       "      <th>runtime</th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>subjects</th>\n",
       "      <th>...</th>\n",
       "      <th>has_prev_appreciate</th>\n",
       "      <th>has_next_appreciate</th>\n",
       "      <th>has_prev_ahead</th>\n",
       "      <th>has_prev_return</th>\n",
       "      <th>has_prev_after this</th>\n",
       "      <th>has_prev_go away</th>\n",
       "      <th>has_next_good evening</th>\n",
       "      <th>has_prev_applause</th>\n",
       "      <th>has_next_applause</th>\n",
       "      <th>has_prev_tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>now the fastest, most reliable internet can he...</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>that's simple, easy, awesome.</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>taxi!</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>should i have stopped her?</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CNNW_20190528_060000_CNN_Newsroom_Live</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>save hundreds of dollars a year when you get i...</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>01:00:58</td>\n",
       "      <td>2019-05-28 06:00:00</td>\n",
       "      <td>2019-05-28 07:00:59</td>\n",
       "      <td>['trump', 'north korea', 'japan', 'rosemary', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                              identifier  start_snip  end_snip  \\\n",
       "0           0  CNNW_20190528_060000_CNN_Newsroom_Live           0        60   \n",
       "1           1  CNNW_20190528_060000_CNN_Newsroom_Live           0        60   \n",
       "2           2  CNNW_20190528_060000_CNN_Newsroom_Live           0        60   \n",
       "3           3  CNNW_20190528_060000_CNN_Newsroom_Live           0        60   \n",
       "4           4  CNNW_20190528_060000_CNN_Newsroom_Live           0        60   \n",
       "\n",
       "                                            sentence contributor   runtime  \\\n",
       "0  now the fastest, most reliable internet can he...        CNNW  01:00:58   \n",
       "1                      that's simple, easy, awesome.        CNNW  01:00:58   \n",
       "2                                              taxi!        CNNW  01:00:58   \n",
       "3                         should i have stopped her?        CNNW  01:00:58   \n",
       "4  save hundreds of dollars a year when you get i...        CNNW  01:00:58   \n",
       "\n",
       "            start_time            stop_time  \\\n",
       "0  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "1  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "2  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "3  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "4  2019-05-28 06:00:00  2019-05-28 07:00:59   \n",
       "\n",
       "                                            subjects  ...  \\\n",
       "0  ['trump', 'north korea', 'japan', 'rosemary', ...  ...   \n",
       "1  ['trump', 'north korea', 'japan', 'rosemary', ...  ...   \n",
       "2  ['trump', 'north korea', 'japan', 'rosemary', ...  ...   \n",
       "3  ['trump', 'north korea', 'japan', 'rosemary', ...  ...   \n",
       "4  ['trump', 'north korea', 'japan', 'rosemary', ...  ...   \n",
       "\n",
       "   has_prev_appreciate  has_next_appreciate  has_prev_ahead  has_prev_return  \\\n",
       "0                  0.0                  0.0             0.0              0.0   \n",
       "1                  0.0                  0.0             0.0              0.0   \n",
       "2                  0.0                  0.0             0.0              0.0   \n",
       "3                  0.0                  0.0             0.0              0.0   \n",
       "4                  0.0                  0.0             0.0              0.0   \n",
       "\n",
       "   has_prev_after this  has_prev_go away  has_next_good evening  \\\n",
       "0                  0.0               0.0                    0.0   \n",
       "1                  0.0               0.0                    0.0   \n",
       "2                  0.0               0.0                    0.0   \n",
       "3                  0.0               0.0                    0.0   \n",
       "4                  0.0               0.0                    0.0   \n",
       "\n",
       "   has_prev_applause  has_next_applause  has_prev_tuned  \n",
       "0                0.0                0.0             0.0  \n",
       "1                0.0                0.0             0.0  \n",
       "2                0.0                0.0             0.0  \n",
       "3                0.0                0.0             0.0  \n",
       "4                0.0                0.0             0.0  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_df = cnn_df.fillna(0)\n",
    "cnn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_df.head(10000).to_csv('../data/interim/cnn_ready_to_code.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_df.iloc[10000:].to_csv('../data/interim/cnn_to_be_tested.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
